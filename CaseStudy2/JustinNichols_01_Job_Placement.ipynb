{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JustinNichols_01- Job Placement.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNuka-TIEKoc"
      },
      "source": [
        "## CSCI 470 Activities and Case Studies\n",
        "\n",
        "1. For all activities, you are allowed to collaborate with a partner. \n",
        "1. For case studies, you should work individually and are **not** allowed to collaborate.\n",
        "\n",
        "By filling out this notebook and submitting it, you acknowledge that you are aware of the above policies and are agreeing to comply with them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbNDV2n4EKod"
      },
      "source": [
        "Some considerations with regard to how these notebooks will be graded:\n",
        "\n",
        "1. You can add more notebook cells or edit existing notebook cells other than \"# YOUR CODE HERE\" to test out or debug your code. We actually highly recommend you do so to gain a better understanding of what is happening. However, during grading, **these changes are ignored**. \n",
        "2. You must ensure that all your code for the particular task is available in the cells that say \"# YOUR CODE HERE\"\n",
        "3. Every cell that says \"# YOUR CODE HERE\" is followed by a \"raise NotImplementedError\". You need to remove that line. During grading, if an error occurs then you will not receive points for your work in that section.\n",
        "4. If your code passes the \"assert\" statements, then no output will result. If your code fails the \"assert\" statements, you will get an \"AssertionError\". Getting an assertion error means you will not receive points for that particular task.\n",
        "5. If you edit the \"assert\" statements to make your code pass, they will still fail when they are graded since the \"assert\" statements will revert to the original. Make sure you don't edit the assert statements.\n",
        "6. We may sometimes have \"hidden\" tests for grading. This means that passing the visible \"assert\" statements is not sufficient. The \"assert\" statements are there as a guide but you need to make sure you understand what you're required to do and ensure that you are doing it correctly. Passing the visible tests is necessary but not sufficient to get the grade for that cell.\n",
        "7. When you are asked to define a function, make sure you **don't** use any variables outside of the parameters passed to the function. You can think of the parameters being passed to the function as a hint. Make sure you're using all of those variables.\n",
        "8. Finally, **make sure you run \"Kernel > Restart and Run All\"** and pass all the asserts before submitting. If you don't restart the kernel, there may be some code that you ran and deleted that is still being used and that was why your asserts were passing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "oTFUB2ZSQriJ",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3eaff0f4eea88447589a984a11f3e2d7",
          "grade": false,
          "grade_id": "cell-c95444a9726cb6ad",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "# Job Performance Prediction\n",
        "\n",
        "You work for a software startup, Predict All The Things Inc. (PALT), and are approached by the CEO to build an algorithm that can help sift through resumes. PALT just closed a $3 million Series A round of funding and the CEO just landed a deal with a national retailer, SellsALOT, to help them with hiring Sales Associates.\n",
        "\n",
        "They are able to obtain data on all the employees that work as Sales Associates throughout their stores as well as customer satisfaction and sales performance scores.\n",
        "\n",
        "In this case study, you are tasked with building a model to predict job performance to assist HR in selecting applicants to interview.\n",
        "\n",
        "The data was provided to you by the new HR intern, Keegan. This is the email you got from Keegan with the attached data.\n",
        "\n",
        ">Hi!\n",
        ">\n",
        ">I hope you're doing well. I've attached the data we have about all employees. Please ensure this data stays confidential and is not shared with anyone who has not signed the NDA. The columns have all the information we have about our employees and the scoring rating that they've received from our performance monitors. We also have some employees who were fired and I have included those as well.\n",
        ">\n",
        ">I was also able to dig up some more information about our employees that I found on the internet. It took a lot of time but I hope it helps in making the model even better. Can't wait to see this thing in action. Everyone here is very excited about our collaboration with you and we look forward to this making hiring a lot easier for us.\n",
        ">\n",
        ">Thanks,\n",
        ">\n",
        ">Keegan Thiel\n",
        ">\n",
        ">HR Intern\n",
        ">\n",
        ">Human Resources\n",
        ">\n",
        ">SellsALOT\n",
        "\n",
        "\n",
        "Data is available in the `employees.csv` file provided. \n",
        "\n",
        "\n",
        "SellsALOT is an Equal Opportunity Employer which is an employer who agrees not to discriminate against any employee or job applicant based on race, color, religion, national origin, sex, physical or mental disability, or age.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCU4JRRt7i44"
      },
      "source": [
        "## Import packages that are likely to be useful\n",
        "\n",
        "### However, __do not__ use TensorFlow to build your models.\n",
        "\n",
        "Below we import packages that are needed or may be useful. You may import additional packages as you see fit, with the exception of TensorFlow. You may use scikit-learn. **Ensure that you import additional packages in cells that say \"### YOUR CODE HERE\".**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "oDynCtWlQriO",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "98d9733673fc16e64c8a56f4f2283337",
          "grade": false,
          "grade_id": "cell-415e7e827876c782",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split\n",
        "import datetime\n",
        "from datetime import date"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "bYxsrpl_QriL",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "36fb3abb8b9d714d711c318557f98208",
          "grade": false,
          "grade_id": "cell-f9469a23a33f582b",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "## Data Cleaning\n",
        "\n",
        "First, let's investigate the data that we received from Keegan.\n",
        "\n",
        "If you are using colab, **Make sure you upload the employees.csv file** so it can be loaded in the next cell. In order to do so, click the file folder icon in the colab sidebar. You will see the contents of the current directory, which will include a \"sample_data\" folder. Click the upload icon (piece of paper with upward pointing arrow, just below the word \"Files\"). Locate the employees.csv file that you downloaded from Canvas to your local machine and open/upload the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "EIfgJtszQriZ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c5e648a7fa9b588f6d9283cfcca4be48",
          "grade": false,
          "grade_id": "cell-2e0e3f39a04d036d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "df = pd.read_csv(\"employees.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHHFixaFQrif",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "89a09e62-04cb-4a8f-b9fb-6f9166db4fd0"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>First Name</th>\n",
              "      <th>Last Name</th>\n",
              "      <th>Date of Birth</th>\n",
              "      <th>Address</th>\n",
              "      <th>Zipcode</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Race / Ethnicity</th>\n",
              "      <th>English Fluency</th>\n",
              "      <th>Spanish Fluency</th>\n",
              "      <th>Education</th>\n",
              "      <th>High School GPA</th>\n",
              "      <th>College GPA</th>\n",
              "      <th>Years of Experience</th>\n",
              "      <th>Years of Volunteering</th>\n",
              "      <th>Myers Briggs Type</th>\n",
              "      <th>Twitter followers</th>\n",
              "      <th>Instagram Followers</th>\n",
              "      <th>Requires Sponsorship</th>\n",
              "      <th>Customer Satisfaction Rating</th>\n",
              "      <th>Sales Rating</th>\n",
              "      <th>Fired</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sarah</td>\n",
              "      <td>Chang</td>\n",
              "      <td>1989-12-24</td>\n",
              "      <td>764 Howard Tunnel</td>\n",
              "      <td>30167</td>\n",
              "      <td>Female</td>\n",
              "      <td>Black</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>Basic</td>\n",
              "      <td>High School</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.52</td>\n",
              "      <td>8.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ISTJ</td>\n",
              "      <td>693</td>\n",
              "      <td>1108</td>\n",
              "      <td>False</td>\n",
              "      <td>2.21</td>\n",
              "      <td>2.07</td>\n",
              "      <td>Current Employee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Daniel</td>\n",
              "      <td>Taylor</td>\n",
              "      <td>1985-03-15</td>\n",
              "      <td>4892 Jessica Turnpike Suite 781</td>\n",
              "      <td>86553</td>\n",
              "      <td>Male</td>\n",
              "      <td>Black</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>Basic</td>\n",
              "      <td>High School</td>\n",
              "      <td>3.02</td>\n",
              "      <td>3.90</td>\n",
              "      <td>13.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ISFJ</td>\n",
              "      <td>507</td>\n",
              "      <td>1259</td>\n",
              "      <td>False</td>\n",
              "      <td>3.37</td>\n",
              "      <td>2.98</td>\n",
              "      <td>Current Employee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Heather</td>\n",
              "      <td>Stewart</td>\n",
              "      <td>1993-09-20</td>\n",
              "      <td>778 Linda Orchard Apt. 609</td>\n",
              "      <td>30167</td>\n",
              "      <td>Female</td>\n",
              "      <td>Black</td>\n",
              "      <td>Proficient</td>\n",
              "      <td>Basic</td>\n",
              "      <td>High School</td>\n",
              "      <td>2.95</td>\n",
              "      <td>2.63</td>\n",
              "      <td>5.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>INFP</td>\n",
              "      <td>599</td>\n",
              "      <td>868</td>\n",
              "      <td>False</td>\n",
              "      <td>1.50</td>\n",
              "      <td>1.36</td>\n",
              "      <td>Current Employee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Katherine</td>\n",
              "      <td>Dillon</td>\n",
              "      <td>1986-12-22</td>\n",
              "      <td>139 Linda Crossroad Suite 115</td>\n",
              "      <td>30167</td>\n",
              "      <td>Female</td>\n",
              "      <td>Black</td>\n",
              "      <td>Basic</td>\n",
              "      <td>Basic</td>\n",
              "      <td>High School</td>\n",
              "      <td>3.99</td>\n",
              "      <td>3.88</td>\n",
              "      <td>12.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ISFP</td>\n",
              "      <td>1321</td>\n",
              "      <td>889</td>\n",
              "      <td>True</td>\n",
              "      <td>2.89</td>\n",
              "      <td>2.62</td>\n",
              "      <td>Current Employee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sheri</td>\n",
              "      <td>Bolton</td>\n",
              "      <td>1991-02-24</td>\n",
              "      <td>1858 Lauren Orchard</td>\n",
              "      <td>60531</td>\n",
              "      <td>Female</td>\n",
              "      <td>Black</td>\n",
              "      <td>Proficient</td>\n",
              "      <td>Proficient</td>\n",
              "      <td>High School</td>\n",
              "      <td>3.82</td>\n",
              "      <td>3.30</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ISFJ</td>\n",
              "      <td>414</td>\n",
              "      <td>13760</td>\n",
              "      <td>True</td>\n",
              "      <td>1.94</td>\n",
              "      <td>1.78</td>\n",
              "      <td>Current Employee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Donna</td>\n",
              "      <td>Davis</td>\n",
              "      <td>1996-05-26</td>\n",
              "      <td>4232 Tina Forks</td>\n",
              "      <td>86553</td>\n",
              "      <td>Female</td>\n",
              "      <td>Black</td>\n",
              "      <td>Proficient</td>\n",
              "      <td>Basic</td>\n",
              "      <td>Associates</td>\n",
              "      <td>2.05</td>\n",
              "      <td>3.14</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ESTJ</td>\n",
              "      <td>495</td>\n",
              "      <td>2401</td>\n",
              "      <td>False</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.87</td>\n",
              "      <td>Current Employee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Benjamin</td>\n",
              "      <td>Shelton</td>\n",
              "      <td>1985-01-15</td>\n",
              "      <td>186 Warren Mount Apt. 396</td>\n",
              "      <td>30167</td>\n",
              "      <td>Male</td>\n",
              "      <td>Black</td>\n",
              "      <td>Proficient</td>\n",
              "      <td>Basic</td>\n",
              "      <td>Associates</td>\n",
              "      <td>2.12</td>\n",
              "      <td>3.51</td>\n",
              "      <td>13.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ESFJ</td>\n",
              "      <td>1696</td>\n",
              "      <td>1158</td>\n",
              "      <td>False</td>\n",
              "      <td>3.41</td>\n",
              "      <td>3.11</td>\n",
              "      <td>Current Employee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Kevin</td>\n",
              "      <td>Hayes</td>\n",
              "      <td>1994-01-21</td>\n",
              "      <td>515 Tucker Plaza Suite 304</td>\n",
              "      <td>59010</td>\n",
              "      <td>Male</td>\n",
              "      <td>Black</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>Basic</td>\n",
              "      <td>High School</td>\n",
              "      <td>2.09</td>\n",
              "      <td>2.92</td>\n",
              "      <td>4.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ESTP</td>\n",
              "      <td>319</td>\n",
              "      <td>538</td>\n",
              "      <td>False</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.29</td>\n",
              "      <td>Current Employee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Autumn</td>\n",
              "      <td>Robinson</td>\n",
              "      <td>1996-05-05</td>\n",
              "      <td>0123 Audrey Union</td>\n",
              "      <td>60531</td>\n",
              "      <td>Female</td>\n",
              "      <td>Black</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>Basic</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ISFJ</td>\n",
              "      <td>988</td>\n",
              "      <td>510</td>\n",
              "      <td>False</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.63</td>\n",
              "      <td>Current Employee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Kimberly</td>\n",
              "      <td>Becker</td>\n",
              "      <td>1983-04-12</td>\n",
              "      <td>91615 Wilson Place</td>\n",
              "      <td>60531</td>\n",
              "      <td>Female</td>\n",
              "      <td>Black</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>Basic</td>\n",
              "      <td>High School</td>\n",
              "      <td>2.99</td>\n",
              "      <td>2.97</td>\n",
              "      <td>14.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>INTP</td>\n",
              "      <td>1169</td>\n",
              "      <td>2254</td>\n",
              "      <td>False</td>\n",
              "      <td>3.59</td>\n",
              "      <td>3.40</td>\n",
              "      <td>Current Employee</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  First Name Last Name  ... Sales Rating             Fired\n",
              "0      Sarah     Chang  ...         2.07  Current Employee\n",
              "1     Daniel    Taylor  ...         2.98  Current Employee\n",
              "2    Heather   Stewart  ...         1.36  Current Employee\n",
              "3  Katherine    Dillon  ...         2.62  Current Employee\n",
              "4      Sheri    Bolton  ...         1.78  Current Employee\n",
              "5      Donna     Davis  ...         0.87  Current Employee\n",
              "6   Benjamin   Shelton  ...         3.11  Current Employee\n",
              "7      Kevin     Hayes  ...         1.29  Current Employee\n",
              "8     Autumn  Robinson  ...         0.63  Current Employee\n",
              "9   Kimberly    Becker  ...         3.40  Current Employee\n",
              "\n",
              "[10 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgby0qLjQrio",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "868ff37d-cfe0-4cb6-920d-8dc4db6839ed"
      },
      "source": [
        "df.describe(include=\"all\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>First Name</th>\n",
              "      <th>Last Name</th>\n",
              "      <th>Date of Birth</th>\n",
              "      <th>Address</th>\n",
              "      <th>Zipcode</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Race / Ethnicity</th>\n",
              "      <th>English Fluency</th>\n",
              "      <th>Spanish Fluency</th>\n",
              "      <th>Education</th>\n",
              "      <th>High School GPA</th>\n",
              "      <th>College GPA</th>\n",
              "      <th>Years of Experience</th>\n",
              "      <th>Years of Volunteering</th>\n",
              "      <th>Myers Briggs Type</th>\n",
              "      <th>Twitter followers</th>\n",
              "      <th>Instagram Followers</th>\n",
              "      <th>Requires Sponsorship</th>\n",
              "      <th>Customer Satisfaction Rating</th>\n",
              "      <th>Sales Rating</th>\n",
              "      <th>Fired</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>1645.000000</td>\n",
              "      <td>1645.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2.000000e+03</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.00000</td>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>477</td>\n",
              "      <td>696</td>\n",
              "      <td>1701</td>\n",
              "      <td>2000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Michael</td>\n",
              "      <td>Smith</td>\n",
              "      <td>1997-06-28</td>\n",
              "      <td>4945 Susan Pass Apt. 771</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Female</td>\n",
              "      <td>Black</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>Basic</td>\n",
              "      <td>High School</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ISFJ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Current Employee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>42</td>\n",
              "      <td>45</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1201</td>\n",
              "      <td>1000</td>\n",
              "      <td>1183</td>\n",
              "      <td>1795</td>\n",
              "      <td>881</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>218</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1813</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>53300.740500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.010359</td>\n",
              "      <td>3.251465</td>\n",
              "      <td>8.042550</td>\n",
              "      <td>0.263000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1065.144500</td>\n",
              "      <td>9.586589e+03</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.220175</td>\n",
              "      <td>2.06511</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17455.384226</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.584502</td>\n",
              "      <td>0.430466</td>\n",
              "      <td>4.674366</td>\n",
              "      <td>0.907487</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7499.266485</td>\n",
              "      <td>2.269563e+05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.058473</td>\n",
              "      <td>0.97946</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24310.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>300.000000</td>\n",
              "      <td>5.000000e+02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>43357.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.510000</td>\n",
              "      <td>2.870000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>364.000000</td>\n",
              "      <td>6.710000e+02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.307500</td>\n",
              "      <td>1.25750</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>55864.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.020000</td>\n",
              "      <td>3.270000</td>\n",
              "      <td>8.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>466.500000</td>\n",
              "      <td>9.925000e+02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>2.06000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60531.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.510000</td>\n",
              "      <td>3.610000</td>\n",
              "      <td>12.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>769.250000</td>\n",
              "      <td>2.042000e+03</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.080000</td>\n",
              "      <td>2.86000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>86553.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>275255.000000</td>\n",
              "      <td>9.798199e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.950000</td>\n",
              "      <td>4.68000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       First Name Last Name  ... Sales Rating             Fired\n",
              "count        2000      2000  ...   2000.00000              2000\n",
              "unique        477       696  ...          NaN                 2\n",
              "top       Michael     Smith  ...          NaN  Current Employee\n",
              "freq           42        45  ...          NaN              1844\n",
              "mean          NaN       NaN  ...      2.06511               NaN\n",
              "std           NaN       NaN  ...      0.97946               NaN\n",
              "min           NaN       NaN  ...      0.00000               NaN\n",
              "25%           NaN       NaN  ...      1.25750               NaN\n",
              "50%           NaN       NaN  ...      2.06000               NaN\n",
              "75%           NaN       NaN  ...      2.86000               NaN\n",
              "max           NaN       NaN  ...      4.68000               NaN\n",
              "\n",
              "[11 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53QCOLGNQriu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56bdca09-d116-4e5d-c8e3-a06db40a5915"
      },
      "source": [
        "print(\"The columns of data are:\")\n",
        "list(df.columns)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The columns of data are:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['First Name',\n",
              " 'Last Name',\n",
              " 'Date of Birth',\n",
              " 'Address',\n",
              " 'Zipcode',\n",
              " 'Gender',\n",
              " 'Race / Ethnicity',\n",
              " 'English Fluency',\n",
              " 'Spanish Fluency',\n",
              " 'Education',\n",
              " 'High School GPA',\n",
              " 'College GPA',\n",
              " 'Years of Experience',\n",
              " 'Years of Volunteering',\n",
              " 'Myers Briggs Type',\n",
              " 'Twitter followers',\n",
              " 'Instagram Followers',\n",
              " 'Requires Sponsorship',\n",
              " 'Customer Satisfaction Rating',\n",
              " 'Sales Rating',\n",
              " 'Fired']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "bwpWFM4JSI1n",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "de79ab46da1ec15d40873fd7c93e4a87",
          "grade": false,
          "grade_id": "cell-da9afb0de2933b89",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Before building any models, your manager has asked you to **convert all the feature data into formats that can easily be used for training and testing a variety of models**. This means:\n",
        "1. Splitting the 16 Myers Briggs types into 4 subtypes\n",
        "2. Converting categorical features into dummy binary features\n",
        "3. Calculating age based on date of birth\n",
        "4. Dealing with missing (NaN) values in the data\n",
        "\n",
        "In addition, you should remove columns that contain redundant information after going through the process above, e.g., removing the 'Date of Birth' column after an 'Age' column is added.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "yyxbe8W2Qri1",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b3b9adb69534d3423b135f54a29bcdf1",
          "grade": false,
          "grade_id": "cell-759ebf896978ca5d",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### MBTI Splitting\n",
        "\n",
        "The [Myers Briggs Type Indicator](https://en.wikipedia.org/wiki/Myers%E2%80%93Briggs_Type_Indicator) (MBTI) descibes people as one of two types for each of:\n",
        "\n",
        "* extraversion (E) or introversion (I)\n",
        "* sensing (S) or intuition (N)\n",
        "* thinking (T) or feeling (F)\n",
        "* judgment (J) or perception (P)\n",
        "\n",
        "It would make more sense for us to represent people as one or the other of these instead of creating all the possible cases. That way a model can learn based on each of those factors as well as their combination. \n",
        "\n",
        "Your next task is to split the MBTI column into four columns in the dataframe, with the following column names and values:\n",
        "\n",
        "* MBTI_EI with value `E` or `I`\n",
        "* MBTI_SN with value `S` or `N`\n",
        "* MBTI_TF with value `T` or `F`\n",
        "* MBTI_JP with value `J` or `P`\n",
        "\n",
        "that correspond to the same row's Myers Briggs Type, and add those columns to your DataFrame, ```df```. Consider using the Series ```apply()``` method.\n",
        "\n",
        "Afterwards, remove the original \"Myers Briggs Type\" column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "IKa0UuiRQri2",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "684f43b481383ae1fa1488100efe524b",
          "grade": false,
          "grade_id": "cell-b96d43f098c26707",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "source": [
        "df['MBTI_EI'] = np.where(df['Myers Briggs Type'].str[0]=='E', 'E', 'I')\n",
        "df['MBTI_SN'] = np.where(df['Myers Briggs Type'].str[1]=='S', 'S', 'N')\n",
        "df['MBTI_TF'] = np.where(df['Myers Briggs Type'].str[2]=='T', 'T', 'F')\n",
        "df['MBTI_JP'] = np.where(df['Myers Briggs Type'].str[3]=='J', 'J', 'P')\n",
        "df.drop(['Myers Briggs Type'], axis=1, inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "5UPBPY9BQri8",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "83708aa6f0dbf9654405634f29adb452",
          "grade": true,
          "grade_id": "cell-1b5cf11c2512def1",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "assert len(set(df[\"MBTI_EI\"])) == 2\n",
        "assert \"E\" in set(df[\"MBTI_EI\"]) and \"I\" in set(df[\"MBTI_EI\"])\n",
        "assert len(set(df[\"MBTI_SN\"])) == 2\n",
        "assert \"S\" in set(df[\"MBTI_SN\"]) and \"N\" in set(df[\"MBTI_SN\"])\n",
        "assert len(set(df[\"MBTI_TF\"])) == 2\n",
        "assert \"T\" in set(df[\"MBTI_TF\"]) and \"F\" in set(df[\"MBTI_TF\"])\n",
        "assert len(set(df[\"MBTI_JP\"])) == 2\n",
        "assert \"J\" in set(df[\"MBTI_JP\"]) and \"P\" in set(df[\"MBTI_JP\"])\n",
        "assert \"Myers Briggs Type\" not in list(df.columns)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Rp7NQOOZQrjA",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d0d66ae39d5eba1acfed519336f95590",
          "grade": false,
          "grade_id": "cell-51a7104ebad2aa72",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "1. ~~Splitting the 16 Myers Briggs types into 4 subtypes~~\n",
        "2. Converting categorical features into dummy binary features\n",
        "3. Calculating age based on date of birth\n",
        "4. Dealing with missing (NaN) values in the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Ee-4-8VnQrjB",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "734ba5de9e3a5df14b8d47fb71753aac",
          "grade": false,
          "grade_id": "cell-364e01542d424264",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Categorical to Dummy Variables\n",
        "\n",
        "Dummy variables are variables that allow us to convert a category into several binary variables. For example, if we had a color value that we were storing and we knew it could only have the values `red`, `green`, and `blue`, then instead of storing the color as those strings, we can store three binary variables: `is_red`, `is_green`, and `is_blue`. \n",
        "\n",
        "We can do this in pandas easily by using [`get_dummies`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "NC0DysIpQrjB",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cddfa9be9a40dbf707ed928596ebb89a",
          "grade": false,
          "grade_id": "cell-32271c292a515ef3",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "source": [
        "# Review the DataFrame columns and identify the columns that contain categorical\n",
        "# features and save them to a list called \"categorical_columns\".\n",
        "\n",
        "# Categorical here means that there is a discrete (albeit large in some cases)\n",
        "# number of possible options for the column that are not just 0 or 1\n",
        "\n",
        "categorical_columns = ['Zipcode', 'Gender', 'Race / Ethnicity', 'English Fluency',\n",
        "                       'Spanish Fluency', 'Education', 'Requires Sponsorship', 'Fired',\n",
        "                       'MBTI_EI', 'MBTI_SN', 'MBTI_TF', 'MBTI_JP']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "jdNtmrl6QrjH",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "18a0f09a797269b018ae2cf0f3e85960",
          "grade": true,
          "grade_id": "cell-528eea88864f2926",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "assert len(categorical_columns) > 8\n",
        "for category in categorical_columns:\n",
        "    assert category in df.columns"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "u-LVPXKCE5rH",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d7053f39a8b8da236f4d5dc09f8fb1ac",
          "grade": false,
          "grade_id": "cell-526438097a7b2b8d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Before we get the dummy variables, we need to make sure that all these \n",
        "# categorical columns are actually recognized by pandas to be of 'category' type.\n",
        "for column in categorical_columns:\n",
        "  \n",
        "    df[column] = df[column].astype('category')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "9nXNaoYeQrjL",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3990d21bd359541639089bd76c03c56b",
          "grade": false,
          "grade_id": "cell-ad307669e4346527",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "source": [
        "# For every column in the categorical_columns,\n",
        "# calculate the dummy variables and add them to the dataframe\n",
        "\n",
        "df = pd.get_dummies(df, columns=categorical_columns)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Wjry6pPNQrjQ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "20a089162c8e028bada006b2ac24c34c",
          "grade": false,
          "grade_id": "cell-d477e9bead9db0a6",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "assert len(list(df.columns)) > 45"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "LYs2UHNUQrjU",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f24fb58ec9e0feb12116a391b973879f",
          "grade": false,
          "grade_id": "cell-4b43f9bb988091cf",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "outputId": "3a2020c0-198d-4157-e8ca-4c26bb862ee0"
      },
      "source": [
        "print(\"The current columns are:\")\n",
        "list(df.columns)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The current columns are:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['First Name',\n",
              " 'Last Name',\n",
              " 'Date of Birth',\n",
              " 'Address',\n",
              " 'High School GPA',\n",
              " 'College GPA',\n",
              " 'Years of Experience',\n",
              " 'Years of Volunteering',\n",
              " 'Twitter followers',\n",
              " 'Instagram Followers',\n",
              " 'Customer Satisfaction Rating',\n",
              " 'Sales Rating',\n",
              " 'Zipcode_24310',\n",
              " 'Zipcode_30167',\n",
              " 'Zipcode_43357',\n",
              " 'Zipcode_43711',\n",
              " 'Zipcode_54821',\n",
              " 'Zipcode_55864',\n",
              " 'Zipcode_59010',\n",
              " 'Zipcode_60531',\n",
              " 'Zipcode_72361',\n",
              " 'Zipcode_86553',\n",
              " 'Gender_Female',\n",
              " 'Gender_Male',\n",
              " 'Race / Ethnicity_Black',\n",
              " 'Race / Ethnicity_Caucasian',\n",
              " 'Race / Ethnicity_Hispanic',\n",
              " 'English Fluency_Basic',\n",
              " 'English Fluency_Fluent',\n",
              " 'English Fluency_Proficient',\n",
              " 'Spanish Fluency_Basic',\n",
              " 'Spanish Fluency_Fluent',\n",
              " 'Spanish Fluency_Proficient',\n",
              " 'Education_Associates',\n",
              " 'Education_Graduate',\n",
              " 'Education_High School',\n",
              " 'Education_None',\n",
              " 'Education_Undergraduate',\n",
              " 'Requires Sponsorship_False',\n",
              " 'Requires Sponsorship_True',\n",
              " 'Fired_Current Employee',\n",
              " 'Fired_Fired',\n",
              " 'MBTI_EI_E',\n",
              " 'MBTI_EI_I',\n",
              " 'MBTI_SN_N',\n",
              " 'MBTI_SN_S',\n",
              " 'MBTI_TF_F',\n",
              " 'MBTI_TF_T',\n",
              " 'MBTI_JP_J',\n",
              " 'MBTI_JP_P']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "2DeBsotIQrja",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b39d0aaf64d919228cd0b7cd681199ba",
          "grade": false,
          "grade_id": "cell-10890eae4243cb8d",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "source": [
        "# Now drop all the categorical features columns from the dataframe\n",
        "# So that we don't have duplicate information stored\n",
        "\n",
        "redundant_features = ['Gender_Female', 'Requires Sponsorship_False', 'Fired_Current Employee', 'MBTI_EI_I', 'MBTI_SN_N', 'MBTI_TF_F', 'MBTI_JP_P']\n",
        "\n",
        "# errors = 'ignore' in case already gone or non-existent i.e., no present observation for binary\n",
        "df.drop(redundant_features, axis=1, inplace=True, errors='ignore')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "EbjQdgc2Qrje",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "10113a2235b4d47c0b3e356e72bbacfa",
          "grade": false,
          "grade_id": "cell-c0598d253d832ddd",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "outputId": "c7f900d5-21b2-4b56-b074-2d68aa04c50a"
      },
      "source": [
        "print(\"The current columns are:\")\n",
        "list(df.columns)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The current columns are:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['First Name',\n",
              " 'Last Name',\n",
              " 'Date of Birth',\n",
              " 'Address',\n",
              " 'High School GPA',\n",
              " 'College GPA',\n",
              " 'Years of Experience',\n",
              " 'Years of Volunteering',\n",
              " 'Twitter followers',\n",
              " 'Instagram Followers',\n",
              " 'Customer Satisfaction Rating',\n",
              " 'Sales Rating',\n",
              " 'Zipcode_24310',\n",
              " 'Zipcode_30167',\n",
              " 'Zipcode_43357',\n",
              " 'Zipcode_43711',\n",
              " 'Zipcode_54821',\n",
              " 'Zipcode_55864',\n",
              " 'Zipcode_59010',\n",
              " 'Zipcode_60531',\n",
              " 'Zipcode_72361',\n",
              " 'Zipcode_86553',\n",
              " 'Gender_Male',\n",
              " 'Race / Ethnicity_Black',\n",
              " 'Race / Ethnicity_Caucasian',\n",
              " 'Race / Ethnicity_Hispanic',\n",
              " 'English Fluency_Basic',\n",
              " 'English Fluency_Fluent',\n",
              " 'English Fluency_Proficient',\n",
              " 'Spanish Fluency_Basic',\n",
              " 'Spanish Fluency_Fluent',\n",
              " 'Spanish Fluency_Proficient',\n",
              " 'Education_Associates',\n",
              " 'Education_Graduate',\n",
              " 'Education_High School',\n",
              " 'Education_None',\n",
              " 'Education_Undergraduate',\n",
              " 'Requires Sponsorship_True',\n",
              " 'Fired_Fired',\n",
              " 'MBTI_EI_E',\n",
              " 'MBTI_SN_S',\n",
              " 'MBTI_TF_T',\n",
              " 'MBTI_JP_J']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "m44-1XHyQrjj",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "87ada951dfc2201e957993b2aa5dbe95",
          "grade": true,
          "grade_id": "cell-a6172310793c3289",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "assert 55 > len(list(df.columns)) > 30"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "COI29UDEQrjn",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "77c1e8cf92655b525a94d6cb6a39c945",
          "grade": false,
          "grade_id": "cell-48ebecdc645e8f6a",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "1. ~~Splitting the 16 Myers Briggs types into 4 subtypes~~\n",
        "2. ~~Converting categorical features into dummy binary features~~\n",
        "3. Calculating age based on date of birth\n",
        "4. Dealing with missing (NaN) values in the data\n",
        "\n",
        "### Age Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "47ydwvFeQrjo",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9db3dce385fe824574de1023425fb7ac",
          "grade": false,
          "grade_id": "cell-028aecaf0638bb7a",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "def calculate_age(born):\n",
        "    \"\"\"Calculates age based on date of birth using https://stackoverflow.com/a/9754466/818687\n",
        "\n",
        "    Args:\n",
        "        born (datetime): The date of birth\n",
        "\n",
        "    Returns:\n",
        "        int: The age based on date of birth\n",
        "    \"\"\"\n",
        "    \n",
        "    today = datetime.datetime.strptime(\"2020-11-20\", \"%Y-%m-%d\")\n",
        "    return today.year - born.year - ((today.month, today.day) < (born.month, born.day))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLuFWRZaQrjs"
      },
      "source": [
        "Add an \"Age\" column to the dataframe, with the help of the ```calculate_age()``` function above. Afterwards, remove the \"Date of Birth\" column.\n",
        "\n",
        "The input to ```calculate_age()``` should be a datetime object. Review the ```datetime.datetme.strptime()```\n",
        "function and [format codes](https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior) to determine how to convert the \"Date of Birth\" date string into a datetime object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "QI7eW-FoQrjs",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f8aa6b8b6f87c947c924722d60becd56",
          "grade": false,
          "grade_id": "cell-315ed06d1f0428b4",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "source": [
        "df['Date of Birth'] = df['Date of Birth'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\"))\n",
        "df['Age'] = df['Date of Birth'].apply(lambda x: calculate_age(x))\n",
        "df.drop(['Date of Birth'], axis=1, inplace=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "2xcfEfy9Qrjv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e7d1e0d2860b91e6231983b6db51a00a",
          "grade": true,
          "grade_id": "cell-abfc46abea98fba7",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "assert df[\"Age\"].min() == 22\n",
        "assert df[\"Age\"].max() == 38\n",
        "assert df[\"Age\"].median() == 30\n",
        "assert \"Date of Birth\" not in list(df.columns)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfVJHz_0C8X6"
      },
      "source": [
        "1. ~~Splitting the 16 Myers Briggs types into 4 subtypes~~\n",
        "2. ~~Converting categorical features into dummy binary features~~\n",
        "3. ~~Calculating age based on date of birth~~\n",
        "4. Dealing with missing (NaN) values in the data\n",
        "\n",
        "## Handle NaN values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPtjdTXjDVOr",
        "outputId": "b3827a38-f0c3-43d1-873e-ff0d68e3e0fb"
      },
      "source": [
        "# Create a list of columns that contain NaN values\n",
        "\n",
        "nan_columns = df.columns[df.isna().any()].tolist()\n",
        "print(nan_columns)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['High School GPA', 'College GPA']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7-lkXhdDmkO"
      },
      "source": [
        "We see that data is not truly \"missing\" any values, but for people that did not attend or complete high school or college, there are no GPA values.\n",
        "\n",
        "How should you deal with this? If you had a large number of people without GPAs, you might consider making separate models for people with GPAs and for people without. For this case, your manager asks you to make sure there's one model for everyone. She recommends one of the following options:\n",
        "\n",
        "1. Replace NaN values with the mean value of all the non-NaN values.\n",
        "1. Replace NaN values with 0\n",
        "1. Replace NaN values with some other value\n",
        "1. Create a model to predict people's GPA values from other attributes and fill them in with those values\n",
        "\n",
        "Consider the assumptions of each approach:\n",
        "1. Replacing with the mean assumes that that person would receive the average of others who work at this company.\n",
        "1. Replacing with 0 assumes that that person would fail if they attended high school or college.\n",
        "1. Replacing with some arbitrary value will have assumptions based on what that value is\n",
        "1. Creating a model to predict people's GPA values from the other attributes in the data assumes that those attributes are predictive of GPA. \n",
        "\n",
        "\n",
        "Regardless of the approach you take, just make sure there are no more NaN values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "ZKJLKs2xE06h",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fd73b92aa5b1a069c528dabd348caa29",
          "grade": false,
          "grade_id": "cell-5b544815d1fa2e03",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# For each of the two columns that contain NaN values, replace the NaN values\n",
        "# with numerical values, using one of the approaches above, or some other approach\n",
        "# that you devise yourself.\n",
        "\n",
        "df[nan_columns] = df[nan_columns].fillna(df[nan_columns].mean())"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "bAi-bCIZFOp9",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f1d84c450a3e75b27f90091cead27b2e",
          "grade": true,
          "grade_id": "cell-06ba496085783976",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "for col in nan_columns:\n",
        "    assert not df[col].isna().any()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3c12534743cf01369960c45d247fc24c",
          "grade": false,
          "grade_id": "cell-7bebafd4a8e5d502",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "d47l5-MLEKod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c80d2271-6004-41bb-f68c-100b5a42359c"
      },
      "source": [
        "# Describe the approach you chose and why and save that as a string called nan_filling_approach\n",
        "\n",
        "nan_filling_approach = \"\"\"My thinking behind this was that since this data is speicific to a job\n",
        "we could expect the employees working there without these values to have somewhere around the mean \n",
        "of the other employees. This implies that they have around the same knowledge is how I interpreted it\"\"\"\n",
        "print(nan_filling_approach)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My thinking behind this was that since this data is speicific to a job\n",
            "we could expect the employees working there without these values to have somewhere around the mean \n",
            "of the other employees. This implies that they have around the same knowledge is how I interpreted it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9fcb6626f13ef89933cdbaffac6171c8",
          "grade": true,
          "grade_id": "cell-e58a09c92fb5074b",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "JQhFSEOrEKod"
      },
      "source": [
        "assert len(nan_filling_approach) > 30"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_52XMEQHMfA"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "5Ehsr1FaQrjz",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5ae89aed737a6106f40120d8fce81e5a",
          "grade": false,
          "grade_id": "cell-ea0c08afcc388389",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Interviewing model(s)\n",
        "\n",
        "Having completed the conversion of the data into a format that can be used with machine learning models, your manager asks that you build three seperate models which predict the following three targets, respectively:\n",
        "\n",
        "1. Customer Satisfaction\n",
        "1. Sales Performance\n",
        "1. Fired"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "KC0mGpc2Qrj0",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3b89b7a9a0df68690eb42725ccbcc45d",
          "grade": false,
          "grade_id": "cell-449eb7f2253cca83",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "source": [
        "# Save the names of columns we are trying to predict to a list called \"targets\".\n",
        "# Make sure that if we had a categorical column, that you use the dummy representation(s)\n",
        "\n",
        "targets = ['Customer Satisfaction Rating', 'Sales Rating', 'Fired_Fired']"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "TDOU2C7ZQrj4",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d5081927389e999a34fec741f4e5b416",
          "grade": true,
          "grade_id": "cell-458aa3767005cc6d",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "assert len(targets) == 3\n",
        "for target in targets:\n",
        "    assert target in df.columns"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "sQ3mnuWzQrj7",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3483b9f94845eb927745bac31e7fd468",
          "grade": false,
          "grade_id": "cell-001c7adb39caf635",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "Ultimately, the predictions of your models will be used to rank applicants for interviews with HR.\n",
        "\n",
        "**Which features will you select to use in your model?** You will specify them below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "bJ1bAdziQrj8",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2ca1e6e7f83ad4da5a3185188c638880",
          "grade": false,
          "grade_id": "cell-e436c6aea590b5c0",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d8d2d7-422b-4b98-c392-834745e6ff23"
      },
      "source": [
        "print(\"The available columns are:\")\n",
        "list(df)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The available columns are:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['First Name',\n",
              " 'Last Name',\n",
              " 'Address',\n",
              " 'High School GPA',\n",
              " 'College GPA',\n",
              " 'Years of Experience',\n",
              " 'Years of Volunteering',\n",
              " 'Twitter followers',\n",
              " 'Instagram Followers',\n",
              " 'Customer Satisfaction Rating',\n",
              " 'Sales Rating',\n",
              " 'Zipcode_24310',\n",
              " 'Zipcode_30167',\n",
              " 'Zipcode_43357',\n",
              " 'Zipcode_43711',\n",
              " 'Zipcode_54821',\n",
              " 'Zipcode_55864',\n",
              " 'Zipcode_59010',\n",
              " 'Zipcode_60531',\n",
              " 'Zipcode_72361',\n",
              " 'Zipcode_86553',\n",
              " 'Gender_Male',\n",
              " 'Race / Ethnicity_Black',\n",
              " 'Race / Ethnicity_Caucasian',\n",
              " 'Race / Ethnicity_Hispanic',\n",
              " 'English Fluency_Basic',\n",
              " 'English Fluency_Fluent',\n",
              " 'English Fluency_Proficient',\n",
              " 'Spanish Fluency_Basic',\n",
              " 'Spanish Fluency_Fluent',\n",
              " 'Spanish Fluency_Proficient',\n",
              " 'Education_Associates',\n",
              " 'Education_Graduate',\n",
              " 'Education_High School',\n",
              " 'Education_None',\n",
              " 'Education_Undergraduate',\n",
              " 'Requires Sponsorship_True',\n",
              " 'Fired_Fired',\n",
              " 'MBTI_EI_E',\n",
              " 'MBTI_SN_S',\n",
              " 'MBTI_TF_T',\n",
              " 'MBTI_JP_J',\n",
              " 'Age']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "_Q71StrCQrkB",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0e494aa6ca038ee3b7d37ef7051bfcdb",
          "grade": false,
          "grade_id": "cell-bd2399d20615cbd1",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "source": [
        "# Enter all the features you want to use in a list and save it to \"interview_features\".\n",
        "# These are the features for the models that will predict the targets, and the\n",
        "# predictions will be used to rank applicants for **interviews**.\n",
        "\n",
        "interview_features = ['High School GPA', 'College GPA',  'Years of Experience', 'Years of Volunteering', 'Twitter followers', 'Instagram Followers', 'English Fluency_Basic', 'English Fluency_Fluent', 'English Fluency_Proficient',\n",
        "                      'Spanish Fluency_Basic', 'Spanish Fluency_Fluent', 'Spanish Fluency_Proficient', 'Education_Associates', 'Education_Graduate', 'Education_High School', 'Education_None', 'Education_Undergraduate',\n",
        "                      'Requires Sponsorship_True', 'Age']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "IEjtob_PQrkE",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "734ba0669bdc3873fb75b67ef74cc737",
          "grade": false,
          "grade_id": "cell-c35210aa72f0c989",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "Why did you choose the features you did?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "szA3hUTVQrkE",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e208d15be2551c27b05dbded87a99da5",
          "grade": false,
          "grade_id": "cell-11725eab2a5dc436",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "source": [
        "## Save your reasoning in a string to the variable interview_reason\n",
        "\n",
        "interview_reason = \"\"\"I didn't think someones ethnicity or gender should be included in picking an applicant, but whether they're fluent in other languages could be important depending on the applicaiton. I felt since we believe so \n",
        "highly in this personality test it would be good to include all of those. Age also feels like an important thing when determining longevity. I didn't include any personal information such as names or location\n",
        "because a name obviously doesn't matter, but location could only matter if the interview wasn't local, or if the person wasn't willing to relocate. I included the followers because I thought it may lead to\n",
        "a representation of how much someone is personable. Even though we replaced the GPA of some people, I felt those were both important. I do believe the appraoch to replacing those could be imporved. On the topic \n",
        "of education, I left those categorical variables in as well. Since sponsorship is important to jobs, I did include that.\"\"\""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "IjjWNMcdQrkH",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f1f846ce7a9241577a65b17e86839b29",
          "grade": true,
          "grade_id": "cell-8b0e41f067c8ef32",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "assert isinstance(interview_reason, str)\n",
        "assert len(interview_reason) > 20"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "uro6564gQrkL",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b04202681097bdf2baa81746a0284884",
          "grade": false,
          "grade_id": "cell-d9d5cf91c533af77",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "source": [
        "# Perform a train and test split on the data with the variable names:\n",
        "# interview_x_train for the training features\n",
        "# interview_x_test for the testing features\n",
        "# interview_y_train for the training targets\n",
        "# interview_y_test for the testing targets\n",
        "# The test dataset should be 20% of the total dataset\n",
        "\n",
        "interview_x_train, interview_x_test, interview_y_train, interview_y_test = train_test_split(df[interview_features], df[targets], test_size=0.2, random_state=0)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "LMrRXdYnQrkN",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1200a735dd6eee29cd1b2c2c94808599",
          "grade": true,
          "grade_id": "cell-146c7b1df2f26d90",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "assert (len(interview_x_train) / (len(interview_x_test) + len(interview_x_train))) == 0.8\n",
        "assert (len(interview_y_train) / (len(interview_y_test) + len(interview_y_train))) == 0.8\n",
        "assert len(interview_x_train) == len(interview_y_train)\n",
        "assert len(interview_x_test) == len(interview_y_test)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkHr4ehrvnqa"
      },
      "source": [
        "Build and train your interviewing models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "7nJGrXs8QrkQ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5e462aa6db1da24ead6274a0ca4859b6",
          "grade": true,
          "grade_id": "cell-99742e48e538f29a",
          "locked": false,
          "points": 50,
          "schema_version": 3,
          "solution": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a464f600-4429-4479-9cad-cb93b0625947"
      },
      "source": [
        "# Select models of your choosing, import them here, and perform a\n",
        "# hyperparameter search while training them on each of the targets.\n",
        "#\n",
        "# Do not use Tensorflow to build a model - you may use scikit-learn.\n",
        "#\n",
        "# Determine an appropriate metric for measuring your performance for each\n",
        "# model/target, and report the test score for that metric. The metric may be\n",
        "# different for each model/target.\n",
        "#\n",
        "# Save your models in a list, with models ordered in the same manner as the\n",
        "# targets they are predicting in the list \"targets\" you created above.\n",
        "# Call the list \"my_hiring_models\", e.g.\n",
        "#    my_interview_models = [interview_model_target1,\n",
        "#                           interview_model_target2,\n",
        "#                           interview_model_target3]\n",
        "#\n",
        "# You should use multiple print messages to print something like the\n",
        "# following for each of your models/targets:\n",
        "#\n",
        "# To predict the target (target), I trained a (model) model\n",
        "# and determined the best hyperparameters as (param1 = p1), (param2 = p2)...\n",
        "# resulting in a (metric) score of (score).\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge, Lasso, LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Customer Satisfaction Rating\n",
        "\n",
        "n_alphas = 50\n",
        "alphas = np.logspace(-5, 0, n_alphas)\n",
        "scoring_metric = \"neg_mean_squared_error\"\n",
        "\n",
        "# Ridge Regression\n",
        "interview_cust_ridge_grid = GridSearchCV(estimator=Ridge(), param_grid=dict(alpha=alphas), scoring=scoring_metric)\n",
        "interview_cust_ridge_grid.fit(interview_x_train, interview_y_train.iloc[:, 0])\n",
        "\n",
        "# Lasso\n",
        "interview_cust_lasso_grid = GridSearchCV(estimator=Lasso(), param_grid=dict(alpha=alphas), scoring=scoring_metric)\n",
        "interview_cust_lasso_grid.fit(interview_x_train, interview_y_train.iloc[:, 0])\n",
        "\n",
        "interview_cust_results = {\n",
        "    'Ridge Regression': -interview_cust_ridge_grid.best_score_,\n",
        "    'Lasso': -interview_cust_lasso_grid.best_score_\n",
        "}\n",
        "\n",
        "print(f\"\"\"To predict the target {interview_y_train.columns[0]}, I trained a {min(interview_cust_results, key=interview_cust_results.get)} model\n",
        "and determined the best hyperparameters as alpha = {interview_cust_lasso_grid.best_params_['alpha']:.6f}\n",
        "resulting in a MSE score of {-interview_cust_lasso_grid.best_score_:.6f}.\\n\"\"\")\n",
        "\n",
        "# Sales Rating\n",
        "\n",
        "# Ridge Regression\n",
        "interview_sales_ridge_grid = GridSearchCV(estimator=Ridge(), param_grid=dict(alpha=alphas), scoring=scoring_metric)\n",
        "interview_sales_ridge_grid.fit(interview_x_train, interview_y_train.iloc[:, 1])\n",
        "\n",
        "# Lasso\n",
        "interview_sales_lasso_grid = GridSearchCV(estimator=Lasso(), param_grid=dict(alpha=alphas), scoring=scoring_metric)\n",
        "interview_sales_lasso_grid.fit(interview_x_train, interview_y_train.iloc[:, 1])\n",
        "\n",
        "interview_sales_results = {\n",
        "    'Ridge Regression': -interview_sales_ridge_grid.best_score_,\n",
        "    'Lasso': -interview_sales_lasso_grid.best_score_\n",
        "}\n",
        "\n",
        "print(f\"\"\"To predict the target {interview_y_train.columns[1]}, I trained a {min(interview_sales_results, key=interview_sales_results.get)} model\n",
        "and determined the best hyperparameters as alpha = {interview_sales_ridge_grid.best_params_['alpha']:.6f}\n",
        "resulting in a MSE score of {-interview_sales_ridge_grid.best_score_:.6f}.\\n\"\"\")\n",
        "\n",
        "# Fired_Fired\n",
        "\n",
        "# SVM\n",
        "svm_params = {\n",
        "    \"C\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e2, 1e3, 1e4],\n",
        "    \"random_state\": [0],\n",
        "    \"gamma\": np.logspace(-5, 0, 7)\n",
        "}\n",
        "interview_fired_svm_grid = GridSearchCV(estimator=SVC(kernel='rbf'), param_grid=svm_params, scoring='accuracy')\n",
        "interview_fired_svm_grid.fit(interview_x_train, interview_y_train.iloc[:, 2])\n",
        "\n",
        "# KNN\n",
        "ks = list(range(1, 21))\n",
        "interview_fired_knn_grid = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=dict(n_neighbors=ks), scoring='accuracy')\n",
        "interview_fired_knn_grid.fit(interview_x_train, interview_y_train.iloc[:, 2])\n",
        "\n",
        "# Logistic Regerssion\n",
        "log_params = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C':[0.001,.009,0.01,.09,1,5,10,25]\n",
        "}\n",
        "\n",
        "interview_fired_log_grid = GridSearchCV(estimator=LogisticRegression(), param_grid=log_params, scoring='accuracy')\n",
        "interview_fired_log_grid.fit(interview_x_train, interview_y_train.iloc[:, 2])\n",
        "\n",
        "interview_fired_results = {\n",
        "    'Support Vector Machine': interview_fired_svm_grid.best_score_,\n",
        "    'K Nearest Neighbors': interview_fired_knn_grid.best_score_,\n",
        "    'Logistic Regression': interview_fired_log_grid.best_score_\n",
        "}\n",
        "\n",
        "print(f\"\"\"To predict the target {interview_y_train.columns[2]}, I trained a {max(interview_fired_results, key=interview_fired_results.get)} model\n",
        "and determined the best hyperparameters as C = {interview_fired_log_grid.best_params_['C']}, with an {interview_fired_log_grid.best_params_['penalty']} penalty\n",
        "resulting in an accuracy score of {interview_fired_log_grid.best_score_:.6f}.\"\"\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To predict the target Customer Satisfaction Rating, I trained a Lasso model\n",
            "and determined the best hyperparameters as alpha = 0.000687\n",
            "resulting in a MSE score of 0.012080.\n",
            "\n",
            "To predict the target Sales Rating, I trained a Ridge Regression model\n",
            "and determined the best hyperparameters as alpha = 0.000010\n",
            "resulting in a MSE score of 0.006842.\n",
            "\n",
            "To predict the target Fired_Fired, I trained a Logistic Regression model\n",
            "and determined the best hyperparameters as C = 25, with an l2 penalty\n",
            "resulting in an accuracy score of 0.935000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvAnN2c4cgH8",
        "outputId": "5fd1d9ab-cc2d-4a1d-91fd-f85637ec5709"
      },
      "source": [
        "interview_cust_results"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Lasso': 0.012080459543189207, 'Ridge Regression': 0.012201737474585592}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5SKredIciD1",
        "outputId": "1b26796d-4550-4c71-e3fa-789cf3c96ed7"
      },
      "source": [
        "interview_sales_results"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Lasso': 0.006843063399610025, 'Ridge Regression': 0.006841580911866799}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96YtoFjjckmH",
        "outputId": "b3d4187e-df2f-4830-ce61-3af925f434d7"
      },
      "source": [
        "interview_fired_results"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'K Nearest Neighbors': 0.93,\n",
              " 'Logistic Regression': 0.9349999999999999,\n",
              " 'Support Vector Machine': 0.93}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIusF0kyPed5"
      },
      "source": [
        "my_interview_models = [interview_cust_lasso_grid.best_estimator_, \n",
        "                       interview_sales_ridge_grid.best_estimator_, \n",
        "                       interview_fired_log_grid.best_estimator_]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkdngUX7yMJq"
      },
      "source": [
        "assert len(my_interview_models)==len(targets)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-4WvDVFYQrkT",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d909350ea6f55a3151827ad93b357df0",
          "grade": false,
          "grade_id": "cell-be0de61adb8d2930",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Hiring model(s)\n",
        "\n",
        "You manager tells you that SellsALOT has decided they wish to consider doing away with interviews altogether, in order to save money. SellsALOT would like a model that will be used to rank candidates for directly hiring them, rather than for interviewing them.\n",
        "\n",
        "Will your choice of features changes?\n",
        "\n",
        "**Which features will you select to use in that model?** You will specify them below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "k2a4ceZsQrkU",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "06aae577c3325934b9dd2d521549d716",
          "grade": false,
          "grade_id": "cell-3aaedae380c7db79",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc510b13-749c-436e-b653-7b45a4b106ca"
      },
      "source": [
        "print(\"The available columns are:\")\n",
        "list(df)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The available columns are:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['First Name',\n",
              " 'Last Name',\n",
              " 'Address',\n",
              " 'High School GPA',\n",
              " 'College GPA',\n",
              " 'Years of Experience',\n",
              " 'Years of Volunteering',\n",
              " 'Twitter followers',\n",
              " 'Instagram Followers',\n",
              " 'Customer Satisfaction Rating',\n",
              " 'Sales Rating',\n",
              " 'Zipcode_24310',\n",
              " 'Zipcode_30167',\n",
              " 'Zipcode_43357',\n",
              " 'Zipcode_43711',\n",
              " 'Zipcode_54821',\n",
              " 'Zipcode_55864',\n",
              " 'Zipcode_59010',\n",
              " 'Zipcode_60531',\n",
              " 'Zipcode_72361',\n",
              " 'Zipcode_86553',\n",
              " 'Gender_Male',\n",
              " 'Race / Ethnicity_Black',\n",
              " 'Race / Ethnicity_Caucasian',\n",
              " 'Race / Ethnicity_Hispanic',\n",
              " 'English Fluency_Basic',\n",
              " 'English Fluency_Fluent',\n",
              " 'English Fluency_Proficient',\n",
              " 'Spanish Fluency_Basic',\n",
              " 'Spanish Fluency_Fluent',\n",
              " 'Spanish Fluency_Proficient',\n",
              " 'Education_Associates',\n",
              " 'Education_Graduate',\n",
              " 'Education_High School',\n",
              " 'Education_None',\n",
              " 'Education_Undergraduate',\n",
              " 'Requires Sponsorship_True',\n",
              " 'Fired_Fired',\n",
              " 'MBTI_EI_E',\n",
              " 'MBTI_SN_S',\n",
              " 'MBTI_TF_T',\n",
              " 'MBTI_JP_J',\n",
              " 'Age']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "ZRyhvmMaQrkW",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "aac9ee0ef0cb43dddc721d66f66eafc6",
          "grade": false,
          "grade_id": "cell-c4bad209682c7022",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "source": [
        "# Enter all the features you want to use in a list and save it to \"hire_features\".\n",
        "# These are the features for the models that will predict the targets, and the\n",
        "# predictions will be used to rank applicants for **hiring**.\n",
        "\n",
        "hire_features = [interview_features[i] for i in [i for i in list(range(19)) if i not in [4, 5, 8, 11, 18] ]]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyYxhGmBM2Vs",
        "outputId": "0cb65730-f0ec-4533-da85-d876c610402b"
      },
      "source": [
        "print('Customer Coefficients:')\n",
        "print(interview_cust_lasso_grid.best_estimator_.sparse_coef_,'\\n')\n",
        "print('Sales Coefficients:')\n",
        "print(interview_sales_lasso_grid.best_estimator_.sparse_coef_)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Customer Coefficients:\n",
            "  (0, 0)\t0.037916673460224995\n",
            "  (0, 1)\t0.057326883661508024\n",
            "  (0, 2)\t0.2133446609510015\n",
            "  (0, 3)\t0.21357734136996426\n",
            "  (0, 4)\t-6.702408547500355e-07\n",
            "  (0, 5)\t1.3176454907048578e-09\n",
            "  (0, 6)\t-0.2017407054379696\n",
            "  (0, 7)\t0.11846417540602998\n",
            "  (0, 9)\t-0.07124045163737841\n",
            "  (0, 10)\t0.02674679033801923\n",
            "  (0, 13)\t0.11760832708624114\n",
            "  (0, 14)\t-0.14705674481054526\n",
            "  (0, 15)\t-0.31645485633291404\n",
            "  (0, 16)\t0.07051610180739529\n",
            "  (0, 18)\t0.0034306621334382168 \n",
            "\n",
            "Sales Coefficients:\n",
            "  (0, 0)\t0.03815621036202474\n",
            "  (0, 1)\t0.049713596130455076\n",
            "  (0, 2)\t0.19255789139742754\n",
            "  (0, 3)\t0.19198179507676527\n",
            "  (0, 4)\t-1.274373282962457e-07\n",
            "  (0, 5)\t-6.516758264568573e-09\n",
            "  (0, 6)\t-0.18821013667816783\n",
            "  (0, 7)\t0.09858188633167422\n",
            "  (0, 9)\t-0.14442816501250588\n",
            "  (0, 10)\t0.050531845928076496\n",
            "  (0, 12)\t0.1590714746675873\n",
            "  (0, 13)\t0.4133140007208122\n",
            "  (0, 14)\t-0.07207101880090003\n",
            "  (0, 15)\t-0.30986721886266433\n",
            "  (0, 16)\t0.2909296197147442\n",
            "  (0, 17)\t0.022654240217137696\n",
            "  (0, 18)\t0.0038155359107959665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Oe68bBEcQrkb",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a6b02cbd6f7418d4619aab8525689ad3",
          "grade": false,
          "grade_id": "cell-b4b87681c2bdc21a",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "Why did you choose the features you did?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "_aT9KBg0Qrkb",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4297c68ae6bc15756a9bd4288edeac7c",
          "grade": true,
          "grade_id": "cell-b95231da655a979d",
          "locked": false,
          "points": 20,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "## Save your reasoning in a string to the variable hire_reason\n",
        "\n",
        "hire_reason = \"\"\"In this model, I took out the five variables that had the small or sparse coefficients associated with the \n",
        "lasso models for both customer and sales ratings\"\"\""
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "WOr6CM_tQrke",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f8ffd07a6c5fa5ea2cb0bb632891a430",
          "grade": true,
          "grade_id": "cell-34d2462a6b2f374c",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "assert isinstance(hire_reason, str)\n",
        "assert len(hire_reason) > 20"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "uKIkN6t-Qrkg",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "517eec5e5592eae3ea6c7ff7c4d63d17",
          "grade": false,
          "grade_id": "cell-5d3c9cf0fe1dac76",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "Why was your choice different from or the same as the interviewing features?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "9NAvxqfvQrkg",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "40c3262507edafa2c79b3db41292b4b1",
          "grade": true,
          "grade_id": "cell-4479d690eeb487ad",
          "locked": false,
          "points": 20,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# Save your reasoning in a string to the variable\n",
        "# same_reason if the features are the same, or\n",
        "# different_reason if the features are different.\n",
        "\n",
        "different_reason = \"\"\"I wanted to make the model selection more strict. Since the lasso method has the ability to \n",
        "act like feature selection, I felt identifying where it zeroed out or has low values were existing for the features\"\"\""
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "rErewAYqQrkl",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "24889e98e4e288ad95c375e3e85655f2",
          "grade": true,
          "grade_id": "cell-f875ee0056d6eb98",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e15cb3f-6102-4aea-b207-4f4eb2221fbd"
      },
      "source": [
        "if all([rf in hire_features for rf in interview_features]) and all([sf in interview_features for sf in hire_features]):\n",
        "    print(\"Your features for interviewing and hiring are the same.\")\n",
        "    assert isinstance(same_reason, str)\n",
        "    assert len(same_reason) > 20\n",
        "else:\n",
        "    print(\"Your features for interviewing and hiring are different.\")\n",
        "    assert isinstance(different_reason, str)\n",
        "    assert len(different_reason) > 20"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your features for interviewing and hiring are different.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "VbuVq9gsQrkn",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "196e9a8b98e5825acd96a0447ca61b55",
          "grade": false,
          "grade_id": "cell-fe98928b7423b02b",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "source": [
        "# Perform a train and test split on the data with the variable names:\n",
        "# hire_x_train for the training features\n",
        "# hire_x_test for the testing features\n",
        "# hire_y_train for the training targets\n",
        "# hire_y_test for the testing targets\n",
        "# The test dataset should be 20% of the total dataset\n",
        "\n",
        "hire_x_train, hire_x_test, hire_y_train, hire_y_test = train_test_split(df[hire_features], df[targets], test_size=0.2, random_state=0)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "pmSR0X0uQrkq",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6724e653238a8d8de046c997f145ec49",
          "grade": true,
          "grade_id": "cell-be29120b1249cd74",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "assert (len(hire_x_train) / (len(hire_x_test) + len(hire_x_train))) == 0.8\n",
        "assert (len(hire_y_train) / (len(hire_y_test) + len(hire_y_train))) == 0.8\n",
        "assert len(hire_x_train) == len(hire_y_train)\n",
        "assert len(hire_x_test) == len(hire_y_test)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "lbc63m_SQrks",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "101ed3dcd7e1ae4166adfe3b64f5919c",
          "grade": false,
          "grade_id": "cell-3ae20ccdd5d080b7",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "Build and train your hiring models.\n",
        "\n",
        "Do you expect this model to perform differently?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "u9vuP3ulQrkt",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "42a7f6265a18b03c5a03f404b938eb16",
          "grade": true,
          "grade_id": "cell-43f1427eb940e017",
          "locked": false,
          "points": 50,
          "schema_version": 3,
          "solution": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f3cd8c-9252-49d9-dd69-113cc25b1069"
      },
      "source": [
        "# Select models of your choosing, import them here, and perform a\n",
        "# hyperparameter search while training them on each of the targets.\n",
        "#\n",
        "# Do not use Tensorflow to build a model - you may use scikit-learn.\n",
        "#\n",
        "# Determine an appropriate metric for measuring your performance for each\n",
        "# model/target, and report the test score for that metric. The metric may be\n",
        "# different for each model/target.\n",
        "#\n",
        "# Save your models in a list, with models ordered in the same manner as the\n",
        "# targets they are predicting in the list \"targets\" you created above.\n",
        "# Call the list \"my_hiring_models\", e.g.\n",
        "#    my_hiring_models = [hiring_model_target1,\n",
        "#                        hiring_model_target2,\n",
        "#                        hiring_model_target3]\n",
        "#\n",
        "# You should use multiple print messages to print something like the\n",
        "# following for each of your models/targets:\n",
        "#\n",
        "# To predict the target (target), I trained a (model) model\n",
        "# and determined the best hyperparameters as (param1 = p1), (param2 = p2)...\n",
        "# resulting in a (metric) score of (score).\n",
        "\n",
        "# Customer Satisfaction Rating\n",
        "\n",
        "# Ridge Regression\n",
        "hire_cust_ridge_grid = GridSearchCV(estimator=Ridge(), param_grid=dict(alpha=alphas), scoring=scoring_metric)\n",
        "hire_cust_ridge_grid.fit(hire_x_train, hire_y_train.iloc[:, 0])\n",
        "\n",
        "# Lasso\n",
        "hire_cust_lasso_grid = GridSearchCV(estimator=Lasso(), param_grid=dict(alpha=alphas), scoring=scoring_metric)\n",
        "hire_cust_lasso_grid.fit(hire_x_train, hire_y_train.iloc[:, 0])\n",
        "\n",
        "hire_cust_results = {\n",
        "    'Ridge Regression': -hire_cust_ridge_grid.best_score_,\n",
        "    'Lasso': -hire_cust_lasso_grid.best_score_\n",
        "}\n",
        "\n",
        "print(f\"\"\"To predict the target {hire_y_train.columns[0]}, I trained a {min(hire_cust_results, key=hire_cust_results.get)} model\n",
        "and determined the best hyperparameters as alpha = {hire_cust_lasso_grid.best_params_['alpha']:.6f}\n",
        "resulting in a MSE score of {-hire_cust_lasso_grid.best_score_:.6f}.\\n\"\"\")\n",
        "\n",
        "# Sales Rating\n",
        "\n",
        "# Ridge Regression\n",
        "hire_sales_ridge_grid = GridSearchCV(estimator=Ridge(), param_grid=dict(alpha=alphas), scoring=scoring_metric)\n",
        "hire_sales_ridge_grid.fit(hire_x_train, hire_y_train.iloc[:, 1])\n",
        "\n",
        "# Lasso\n",
        "hire_sales_lasso_grid = GridSearchCV(estimator=Lasso(), param_grid=dict(alpha=alphas), scoring=scoring_metric)\n",
        "hire_sales_lasso_grid.fit(hire_x_train, hire_y_train.iloc[:, 1])\n",
        "\n",
        "hire_sales_results = {\n",
        "    'Ridge Regression': -hire_sales_ridge_grid.best_score_,\n",
        "    'Lasso': -hire_sales_lasso_grid.best_score_\n",
        "}\n",
        "\n",
        "print(f\"\"\"To predict the target {hire_y_train.columns[1]}, I trained a {min(hire_sales_results, key=hire_sales_results.get)} model\n",
        "and determined the best hyperparameters as alpha = {hire_sales_ridge_grid.best_params_['alpha']:.6f}\n",
        "resulting in a MSE score of {-hire_sales_ridge_grid.best_score_:.6f}.\\n\"\"\")\n",
        "\n",
        "# Fired_Fired\n",
        "\n",
        "# SVM\n",
        "hire_fired_svm_grid = GridSearchCV(estimator=SVC(kernel='rbf'), param_grid=svm_params, scoring='accuracy')\n",
        "hire_fired_svm_grid.fit(hire_x_train, hire_y_train.iloc[:, 2])\n",
        "\n",
        "# KNN\n",
        "hire_fired_knn_grid = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=dict(n_neighbors=ks), scoring='accuracy')\n",
        "hire_fired_knn_grid.fit(hire_x_train, hire_y_train.iloc[:, 2])\n",
        "\n",
        "# Logistic Regerssion\n",
        "hire_fired_log_grid = GridSearchCV(estimator=LogisticRegression(), param_grid=log_params, scoring='accuracy')\n",
        "hire_fired_log_grid.fit(hire_x_train, hire_y_train.iloc[:, 2])\n",
        "\n",
        "hire_fired_results = {\n",
        "    'Support Vector Machine': hire_fired_svm_grid.best_score_,\n",
        "    'K Nearest Neighbors': hire_fired_knn_grid.best_score_,\n",
        "    'Logistic Regression': hire_fired_log_grid.best_score_\n",
        "}\n",
        "\n",
        "print(f\"\"\"To predict the target {hire_y_train.columns[2]}, I trained a {max(hire_fired_results, key=hire_fired_results.get)} model\n",
        "and determined the best hyperparameters as K = {hire_fired_knn_grid.best_params_['n_neighbors']}\n",
        "resulting in an accuracy score of {hire_fired_knn_grid.best_score_:.6f}.\"\"\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To predict the target Customer Satisfaction Rating, I trained a Lasso model\n",
            "and determined the best hyperparameters as alpha = 0.000212\n",
            "resulting in a MSE score of 0.007443.\n",
            "\n",
            "To predict the target Sales Rating, I trained a Ridge Regression model\n",
            "and determined the best hyperparameters as alpha = 0.152642\n",
            "resulting in a MSE score of 0.006470.\n",
            "\n",
            "To predict the target Fired_Fired, I trained a K Nearest Neighbors model\n",
            "and determined the best hyperparameters as K = 9\n",
            "resulting in an accuracy score of 0.967500.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQKzlgL6cYLw",
        "outputId": "90b983cf-e276-4ff2-96c6-ae90fe7648fe"
      },
      "source": [
        "hire_cust_results"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Lasso': 0.007442567656380475, 'Ridge Regression': 0.007447448771292197}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWPuJrPAe1dj",
        "outputId": "c2fd1b3a-7aca-4dee-a957-a4e2e0b81619"
      },
      "source": [
        "hire_sales_results"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Lasso': 0.006469602647378789, 'Ridge Regression': 0.006469573420238262}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daYaDvz8cdOW",
        "outputId": "405fd1e1-e95b-4952-d316-12cdd0258370"
      },
      "source": [
        "hire_fired_results"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'K Nearest Neighbors': 0.9675,\n",
              " 'Logistic Regression': 0.9362499999999999,\n",
              " 'Support Vector Machine': 0.9650000000000001}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTTl83H_eer2"
      },
      "source": [
        "my_hiring_models = [hire_cust_lasso_grid.best_estimator_, hire_sales_ridge_grid.best_estimator_, hire_fired_knn_grid.best_estimator_]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCxIICXkyZu-"
      },
      "source": [
        "assert len(my_hiring_models)==len(targets)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "21INaL-DQrkv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6cb417be848f300a556608b9c30d9198",
          "grade": true,
          "grade_id": "cell-5df6d98d3b874670",
          "locked": false,
          "points": 20,
          "schema_version": 3,
          "solution": true
        }
      },
      "source": [
        "# Follow this up with a comparison between the performance (test scores) on your\n",
        "# two sets of models.\n",
        "#\n",
        "# You should print something like, for each of the targets:\n",
        "#   Using interview features for target (target) the model scored (score)\n",
        "#   versus using the hiring features where it scored (score)\n",
        "\n",
        "final_cust_results = pd.DataFrame(\n",
        "    np.array([list(interview_cust_results.values()),\n",
        "              list(hire_cust_results.values())]),\n",
        "    index=['Interview Models', 'Hire Models'],\n",
        "    columns=['Ridge Reression MSE', 'Lasso MSE']\n",
        ")\n",
        "final_sales_results = pd.DataFrame(\n",
        "    np.array([list(interview_sales_results.values()),\n",
        "              list(hire_sales_results.values())]),\n",
        "    index=['Interview Models', 'Hire Models'],\n",
        "    columns=['Ridge Reression MSE', 'Lasso MSE']\n",
        ")\n",
        "final_fired_results = pd.DataFrame(\n",
        "    np.array([list(interview_fired_results.values()),\n",
        "              list(hire_fired_results.values())]),\n",
        "    index=['Interview Models', 'Hire Models'],\n",
        "    columns=['Support Vector Machine', 'K Nearest Neighbors', 'Logistic Regression']\n",
        ")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "e2P-1I7yjvm-",
        "outputId": "44f98c02-f1c9-4654-ce8e-730099c646a5"
      },
      "source": [
        "final_cust_results"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ridge Reression MSE</th>\n",
              "      <th>Lasso MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Interview Models</th>\n",
              "      <td>0.012202</td>\n",
              "      <td>0.012080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hire Models</th>\n",
              "      <td>0.007447</td>\n",
              "      <td>0.007443</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Ridge Reression MSE  Lasso MSE\n",
              "Interview Models             0.012202   0.012080\n",
              "Hire Models                  0.007447   0.007443"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "5fnxZN0djvub",
        "outputId": "b634c43a-f853-4345-aaf6-a3af250840f3"
      },
      "source": [
        "final_sales_results"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ridge Reression MSE</th>\n",
              "      <th>Lasso MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Interview Models</th>\n",
              "      <td>0.006842</td>\n",
              "      <td>0.006843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hire Models</th>\n",
              "      <td>0.006470</td>\n",
              "      <td>0.006470</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Ridge Reression MSE  Lasso MSE\n",
              "Interview Models             0.006842   0.006843\n",
              "Hire Models                  0.006470   0.006470"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "1rsaUp5FjwH2",
        "outputId": "3df08699-a140-404f-f3d2-87ab990b4f3d"
      },
      "source": [
        "final_fired_results"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Support Vector Machine</th>\n",
              "      <th>K Nearest Neighbors</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Interview Models</th>\n",
              "      <td>0.930</td>\n",
              "      <td>0.9300</td>\n",
              "      <td>0.93500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hire Models</th>\n",
              "      <td>0.965</td>\n",
              "      <td>0.9675</td>\n",
              "      <td>0.93625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Support Vector Machine  ...  Logistic Regression\n",
              "Interview Models                   0.930  ...              0.93500\n",
              "Hire Models                        0.965  ...              0.93625\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOB_29ZQDa5r"
      },
      "source": [
        "## Model Evaluation\n",
        "\n",
        "In this section we'll create example applicants and see how they would fare based on their applications and your models. First, let's create some example applications. We've created four applicants, and you'll need to create a fifth one in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "I_mNuuafD1ID",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1b633f680d8268103d3467dff7fc146b",
          "grade": false,
          "grade_id": "cell-f8b4174a433caec6",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "applicant_1 = {\n",
        "    'First Name': \"Stefon\",\n",
        "    'Last Name': \"Smith\",\n",
        "    'Date of Birth': \"1989-12-24\",\n",
        "    'Address': \"4892 Jessica Turnpike Suite 781\",\n",
        "    'Zipcode': 86553,\n",
        "    'Gender': \"Male\",\n",
        "    'Race / Ethnicity': \"Caucasian\",\n",
        "    'English Fluency': \"Proficient\",\n",
        "    'Spanish Fluency': \"Basic\",\n",
        "    'Education': \"Associates\",\n",
        "    'High School GPA': 2.9,\n",
        "    'College GPA': 3.1,\n",
        "    'Years of Experience': 5,\n",
        "    'Years of Volunteering': 2,\n",
        "    'Myers Briggs Type': \"ESFJ\",\n",
        "    'Twitter followers': 524,\n",
        "    'Instagram Followers': 857,\n",
        "    'Requires Sponsorship': True\n",
        "}\n",
        "applicant_2 = {\n",
        "    'First Name': \"Sarah\",\n",
        "    'Last Name': \"Chang\",\n",
        "    'Date of Birth': \"1995-04-13\",\n",
        "    'Address': \"9163 Rebecca Loop\",\n",
        "    'Zipcode': 43711,\n",
        "    'Gender': \"Female\",\n",
        "    'Race / Ethnicity': \"Hispanic\",\n",
        "    'English Fluency': \"Fluent\",\n",
        "    'Spanish Fluency': \"Fluent\",\n",
        "    'Education': \"Undergraduate\",\n",
        "    'High School GPA': 4.0,\n",
        "    'College GPA': 3.8,\n",
        "    'Years of Experience': 5,\n",
        "    'Years of Volunteering': 0,\n",
        "    'Myers Briggs Type': \"ISTJ\",\n",
        "    'Twitter followers': 97,\n",
        "    'Instagram Followers': 204,\n",
        "    'Requires Sponsorship': False\n",
        "}\n",
        "applicant_3 = {\n",
        "    'First Name': \"Daniel\",\n",
        "    'Last Name': \"Richardson\",\n",
        "    'Date of Birth': \"1998-10-23\",\n",
        "    'Address': \"436 Lauren Stream\",\n",
        "    'Zipcode': 54821,\n",
        "    'Gender': \"Male\",\n",
        "    'Race / Ethnicity': \"Black\",\n",
        "    'English Fluency': \"Fluent\",\n",
        "    'Spanish Fluency': \"Proficient\",\n",
        "    'Education': \"Undergraduate\",\n",
        "    'High School GPA': 3.0,\n",
        "    'College GPA': 3.2,\n",
        "    'Years of Experience': 1,\n",
        "    'Years of Volunteering': 1,\n",
        "    'Myers Briggs Type': \"ENFJ\",\n",
        "    'Twitter followers': 2087,\n",
        "    'Instagram Followers': 3211,\n",
        "    'Requires Sponsorship': False\n",
        "}\n",
        "\n",
        "applicant_4 = {\n",
        "    'First Name': \"Billy\",\n",
        "    'Last Name': \"Bob\",\n",
        "    'Date of Birth': \"1999-11-03\",\n",
        "    'Address': \"412 Railway Stream\",\n",
        "    'Zipcode': 43711,\n",
        "    'Gender': \"Male\",\n",
        "    'Race / Ethnicity': \"Caucasian\",\n",
        "    'English Fluency': \"Basic\",\n",
        "    'Spanish Fluency': \"Fluent\",\n",
        "    'Education': \"Undergraduate\",\n",
        "    'High School GPA': 2.0,\n",
        "    'College GPA': 3.5,\n",
        "    'Years of Experience': 1,\n",
        "    'Years of Volunteering': 1,\n",
        "    'Myers Briggs Type': \"ENFJ\",\n",
        "    'Twitter followers': 207,\n",
        "    'Instagram Followers': 309,\n",
        "    'Requires Sponsorship': False\n",
        "}\n",
        "\n",
        "# Create a fictional applicant by copying the attributes above from any of the\n",
        "# other applicants and/or adding example values that you would be curious to\n",
        "# see how your model treats. For example, create an applicant you'd be sure to\n",
        "# reject or sure to hire.\n",
        "\n",
        "applicant_5 = {\n",
        "    'First Name': \"Billy\",\n",
        "    'Last Name': \"Goat\",\n",
        "    'Date of Birth': \"1999-09-25\",\n",
        "    'Address': \"1050 Secrest St\",\n",
        "    'Zipcode': 80401,\n",
        "    'Gender': \"Male\",\n",
        "    'Race / Ethnicity': \"Caucasian\",\n",
        "    'English Fluency': \"Fluent\",\n",
        "    'Spanish Fluency': \"Basic\",\n",
        "    'Education': \"None\",\n",
        "    'High School GPA': 3.0,\n",
        "    'College GPA': 1.94,\n",
        "    'Years of Experience': 0,\n",
        "    'Years of Volunteering': 0,\n",
        "    'Myers Briggs Type': \"ENFJ\",\n",
        "    'Twitter followers': 0,\n",
        "    'Instagram Followers': 0,\n",
        "    'Requires Sponsorship': False\n",
        "}"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "VvWLYqtEUE9q",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8d75f1550e13541f1e138be0f5dd7393",
          "grade": true,
          "grade_id": "cell-5a2332a45ba35b42",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "for key in applicant_4.keys():\n",
        "    assert key in applicant_5.keys()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "BXqD3wgDD1PX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a06031e5e9f4360db064b4fc753fb49b",
          "grade": false,
          "grade_id": "cell-2cf93863baeae2d9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "new_people = [applicant_1, applicant_2, applicant_3, applicant_4, applicant_5]\n",
        "new_people_df = pd.DataFrame.from_records(new_people)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "IN_pmgpAoX5r",
        "outputId": "962a5481-3719-4d6a-d7f3-bd02842d9c4f"
      },
      "source": [
        "new_people_df"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>First Name</th>\n",
              "      <th>Last Name</th>\n",
              "      <th>Date of Birth</th>\n",
              "      <th>Address</th>\n",
              "      <th>Zipcode</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Race / Ethnicity</th>\n",
              "      <th>English Fluency</th>\n",
              "      <th>Spanish Fluency</th>\n",
              "      <th>Education</th>\n",
              "      <th>High School GPA</th>\n",
              "      <th>College GPA</th>\n",
              "      <th>Years of Experience</th>\n",
              "      <th>Years of Volunteering</th>\n",
              "      <th>Myers Briggs Type</th>\n",
              "      <th>Twitter followers</th>\n",
              "      <th>Instagram Followers</th>\n",
              "      <th>Requires Sponsorship</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stefon</td>\n",
              "      <td>Smith</td>\n",
              "      <td>1989-12-24</td>\n",
              "      <td>4892 Jessica Turnpike Suite 781</td>\n",
              "      <td>86553</td>\n",
              "      <td>Male</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Proficient</td>\n",
              "      <td>Basic</td>\n",
              "      <td>Associates</td>\n",
              "      <td>2.9</td>\n",
              "      <td>3.10</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>ESFJ</td>\n",
              "      <td>524</td>\n",
              "      <td>857</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sarah</td>\n",
              "      <td>Chang</td>\n",
              "      <td>1995-04-13</td>\n",
              "      <td>9163 Rebecca Loop</td>\n",
              "      <td>43711</td>\n",
              "      <td>Female</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>Undergraduate</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.80</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>ISTJ</td>\n",
              "      <td>97</td>\n",
              "      <td>204</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Daniel</td>\n",
              "      <td>Richardson</td>\n",
              "      <td>1998-10-23</td>\n",
              "      <td>436 Lauren Stream</td>\n",
              "      <td>54821</td>\n",
              "      <td>Male</td>\n",
              "      <td>Black</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>Proficient</td>\n",
              "      <td>Undergraduate</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.20</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ENFJ</td>\n",
              "      <td>2087</td>\n",
              "      <td>3211</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Billy</td>\n",
              "      <td>Bob</td>\n",
              "      <td>1999-11-03</td>\n",
              "      <td>412 Railway Stream</td>\n",
              "      <td>43711</td>\n",
              "      <td>Male</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Basic</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>Undergraduate</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.50</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ENFJ</td>\n",
              "      <td>207</td>\n",
              "      <td>309</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Billy</td>\n",
              "      <td>Goat</td>\n",
              "      <td>1999-09-25</td>\n",
              "      <td>1050 Secrest St</td>\n",
              "      <td>80401</td>\n",
              "      <td>Male</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Fluent</td>\n",
              "      <td>Basic</td>\n",
              "      <td>None</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.94</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ENFJ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  First Name   Last Name  ... Instagram Followers Requires Sponsorship\n",
              "0     Stefon       Smith  ...                 857                 True\n",
              "1      Sarah       Chang  ...                 204                False\n",
              "2     Daniel  Richardson  ...                3211                False\n",
              "3      Billy         Bob  ...                 309                False\n",
              "4      Billy        Goat  ...                   0                False\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7izcLclbHjNA"
      },
      "source": [
        "### Future Applicants Data Cleaning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "Ue9L02lED1Xn",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "823bca69f4da6cc87e4800ff6d74e8f3",
          "grade": false,
          "grade_id": "cell-e8d9072c79ce7dab",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# Apply all the cleaning and dummy variable creation you did above to this new\n",
        "# DataFrame. You can copy your code from above and modify it to apply to\n",
        "# new_people_df instead of df.\n",
        "\n",
        "new_people_df['MBTI_EI'] = np.where(new_people_df['Myers Briggs Type'].str[0]=='E', 'E', 'I')\n",
        "new_people_df['MBTI_SN'] = np.where(new_people_df['Myers Briggs Type'].str[1]=='S', 'S', 'N')\n",
        "new_people_df['MBTI_TF'] = np.where(new_people_df['Myers Briggs Type'].str[2]=='T', 'T', 'F')\n",
        "new_people_df['MBTI_JP'] = np.where(new_people_df['Myers Briggs Type'].str[3]=='J', 'J', 'P')\n",
        "new_people_df.drop(['Myers Briggs Type'], axis=1, inplace=True)\n",
        "\n",
        "categorical_columns = ['Zipcode', 'Gender', 'Race / Ethnicity', 'English Fluency',\n",
        "                       'Spanish Fluency', 'Education', 'Requires Sponsorship',\n",
        "                       'MBTI_EI', 'MBTI_SN', 'MBTI_TF', 'MBTI_JP']\n",
        "for column in categorical_columns:\n",
        "    new_people_df[column] = new_people_df[column].astype('category')\n",
        "\n",
        "new_people_df = pd.get_dummies(new_people_df, columns=categorical_columns)\n",
        "for column in interview_features:\n",
        "  if column not in new_people_df.columns:\n",
        "    new_people_df[column] = 0\n",
        "\n",
        "redundant_features = ['Gender_Female', 'Requires Sponsorship_False', 'MBTI_EI_I', 'MBTI_SN_N', 'MBTI_TF_F', 'MBTI_JP_P']\n",
        "new_people_df.drop(redundant_features, axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "new_people_df['Date of Birth'] = new_people_df['Date of Birth'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\"))\n",
        "new_people_df['Age'] = new_people_df['Date of Birth'].apply(lambda x: calculate_age(x))\n",
        "new_people_df.drop(['Date of Birth'], axis=1, inplace=True)                       "
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWmLMqEUmbpg"
      },
      "source": [
        "nan_columns = new_people_df.columns[new_people_df.isna().any()].tolist()\n",
        "new_people_df[nan_columns] = new_people_df[nan_columns].fillna(new_people_df[nan_columns].mean())"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "DKqfnjPeqOgh",
        "outputId": "e59f097f-df41-4923-e812-b90538ef5954"
      },
      "source": [
        "new_people_df"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>First Name</th>\n",
              "      <th>Last Name</th>\n",
              "      <th>Address</th>\n",
              "      <th>High School GPA</th>\n",
              "      <th>College GPA</th>\n",
              "      <th>Years of Experience</th>\n",
              "      <th>Years of Volunteering</th>\n",
              "      <th>Twitter followers</th>\n",
              "      <th>Instagram Followers</th>\n",
              "      <th>Zipcode_43711</th>\n",
              "      <th>Zipcode_54821</th>\n",
              "      <th>Zipcode_80401</th>\n",
              "      <th>Zipcode_86553</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Race / Ethnicity_Black</th>\n",
              "      <th>Race / Ethnicity_Caucasian</th>\n",
              "      <th>Race / Ethnicity_Hispanic</th>\n",
              "      <th>English Fluency_Basic</th>\n",
              "      <th>English Fluency_Fluent</th>\n",
              "      <th>English Fluency_Proficient</th>\n",
              "      <th>Spanish Fluency_Basic</th>\n",
              "      <th>Spanish Fluency_Fluent</th>\n",
              "      <th>Spanish Fluency_Proficient</th>\n",
              "      <th>Education_Associates</th>\n",
              "      <th>Education_None</th>\n",
              "      <th>Education_Undergraduate</th>\n",
              "      <th>Requires Sponsorship_True</th>\n",
              "      <th>MBTI_EI_E</th>\n",
              "      <th>MBTI_SN_S</th>\n",
              "      <th>MBTI_TF_T</th>\n",
              "      <th>MBTI_JP_J</th>\n",
              "      <th>Education_Graduate</th>\n",
              "      <th>Education_High School</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stefon</td>\n",
              "      <td>Smith</td>\n",
              "      <td>4892 Jessica Turnpike Suite 781</td>\n",
              "      <td>2.9</td>\n",
              "      <td>3.10</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>524</td>\n",
              "      <td>857</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sarah</td>\n",
              "      <td>Chang</td>\n",
              "      <td>9163 Rebecca Loop</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.80</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>97</td>\n",
              "      <td>204</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Daniel</td>\n",
              "      <td>Richardson</td>\n",
              "      <td>436 Lauren Stream</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.20</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2087</td>\n",
              "      <td>3211</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Billy</td>\n",
              "      <td>Bob</td>\n",
              "      <td>412 Railway Stream</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.50</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>207</td>\n",
              "      <td>309</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Billy</td>\n",
              "      <td>Goat</td>\n",
              "      <td>1050 Secrest St</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.94</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  First Name   Last Name  ... Education_High School  Age\n",
              "0     Stefon       Smith  ...                     0   30\n",
              "1      Sarah       Chang  ...                     0   25\n",
              "2     Daniel  Richardson  ...                     0   22\n",
              "3      Billy         Bob  ...                     0   21\n",
              "4      Billy        Goat  ...                     0   21\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "fp8p3gdiD1NN",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "851b90d71f4377ba57be9db912cca89d",
          "grade": true,
          "grade_id": "cell-f9226b28d96f00a8",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "for feature in interview_features:\n",
        "    assert feature in new_people_df.columns\n",
        "for feature in hire_features:\n",
        "    assert feature in new_people_df.columns"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUfDigqdHir7"
      },
      "source": [
        "### Future Applicant Model(s) Predictions\n",
        "\n",
        "Now let's predict what the applicants' scores would be. Use your `best_interview_model` and `best_hire_model` to predict their scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "yDbBZnIvHTGq",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "138d3d03cc063c83b89a4cf2212d5d54",
          "grade": false,
          "grade_id": "cell-8ecd71076203ea0e",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# Save your predictions as new_people_interview and new_people_hire.\n",
        "# Each of these should be a list of dictionaries, with one dictionery for\n",
        "# each applicant. The keys of the dictionaries should be the same as the\n",
        "# elements/strings in the \"targets\" list you created above.\n",
        "\n",
        "new_people_interview_features = new_people_df[interview_features]\n",
        "new_people_hire_features = new_people_df[hire_features]\n",
        "\n",
        "\n",
        "interview_cust_pred = my_interview_models[0].predict(new_people_interview_features)\n",
        "interview_sales_pred = my_interview_models[1].predict(new_people_interview_features)\n",
        "interview_fired_pred = my_interview_models[2].predict(new_people_interview_features)\n",
        "new_people_interview = [{targets[0]: interview_cust_pred[0],\n",
        "                         targets[1]: interview_sales_pred[0],\n",
        "                         targets[2]: interview_fired_pred[0]},\n",
        "                        {targets[0]: interview_cust_pred[1],\n",
        "                         targets[1]: interview_sales_pred[1],\n",
        "                         targets[2]: interview_fired_pred[1]},\n",
        "                        {targets[0]: interview_cust_pred[2],\n",
        "                         targets[1]: interview_sales_pred[2],\n",
        "                         targets[2]: interview_fired_pred[2]},\n",
        "                        {targets[0]: interview_cust_pred[3],\n",
        "                         targets[1]: interview_sales_pred[3],\n",
        "                         targets[2]: interview_fired_pred[3]},\n",
        "                        {targets[0]: interview_cust_pred[4],\n",
        "                         targets[1]: interview_sales_pred[4],\n",
        "                         targets[2]: interview_fired_pred[4]}]\n",
        "\n",
        "hire_cust_pred = my_hiring_models[0].predict(new_people_hire_features)\n",
        "hire_sales_pred = my_hiring_models[1].predict(new_people_hire_features)\n",
        "hire_fired_pred = my_hiring_models[2].predict(new_people_hire_features)\n",
        "new_people_hire = [{targets[0]: hire_cust_pred[0],\n",
        "                         targets[1]: hire_sales_pred[0],\n",
        "                         targets[2]: hire_fired_pred[0]},\n",
        "                        {targets[0]: hire_cust_pred[1],\n",
        "                         targets[1]: hire_sales_pred[1],\n",
        "                         targets[2]: hire_fired_pred[1]},\n",
        "                        {targets[0]: hire_cust_pred[2],\n",
        "                         targets[1]: hire_sales_pred[2],\n",
        "                         targets[2]: hire_fired_pred[2]},\n",
        "                        {targets[0]: hire_cust_pred[3],\n",
        "                         targets[1]: hire_sales_pred[3],\n",
        "                         targets[2]: hire_fired_pred[3]},\n",
        "                        {targets[0]: hire_cust_pred[4],\n",
        "                         targets[1]: hire_sales_pred[4],\n",
        "                         targets[2]: hire_fired_pred[4]}]                         "
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA7MxEL_wvMm",
        "outputId": "2dee2689-c62b-4acf-81be-f1bda70f9be9"
      },
      "source": [
        "new_people_interview"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Customer Satisfaction Rating': 1.9936867449458988,\n",
              "  'Fired_Fired': 0,\n",
              "  'Sales Rating': 1.9382944647355316},\n",
              " {'Customer Satisfaction Rating': 1.918468762519378,\n",
              "  'Fired_Fired': 0,\n",
              "  'Sales Rating': 2.0150816590613996},\n",
              " {'Customer Satisfaction Rating': 1.1679860625489105,\n",
              "  'Fired_Fired': 0,\n",
              "  'Sales Rating': 1.3062773011243294},\n",
              " {'Customer Satisfaction Rating': 0.8516349305474354,\n",
              "  'Fired_Fired': 0,\n",
              "  'Sales Rating': 1.0434187523468657},\n",
              " {'Customer Satisfaction Rating': 0.20858467660751143,\n",
              "  'Fired_Fired': 0,\n",
              "  'Sales Rating': 0.11012494787581634}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8aqPX1z6mdb",
        "outputId": "c3c7fdc0-9d72-4280-a2ca-59d55115d369"
      },
      "source": [
        "new_people_hire"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Customer Satisfaction Rating': 1.9821925225530626,\n",
              "  'Fired_Fired': 0,\n",
              "  'Sales Rating': 1.926226365525524},\n",
              " {'Customer Satisfaction Rating': 1.9418280526308513,\n",
              "  'Fired_Fired': 0,\n",
              "  'Sales Rating': 2.0198036936068458},\n",
              " {'Customer Satisfaction Rating': 1.175339140798052,\n",
              "  'Fired_Fired': 0,\n",
              "  'Sales Rating': 1.3088800584141764},\n",
              " {'Customer Satisfaction Rating': 0.8705701186266215,\n",
              "  'Fired_Fired': 0,\n",
              "  'Sales Rating': 1.0493949418949342},\n",
              " {'Customer Satisfaction Rating': 0.20379951179270311,\n",
              "  'Fired_Fired': 1,\n",
              "  'Sales Rating': 0.11314320638861647}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "rooCaeaeHzjX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0d8e0f1f97905aa3f29301220a68f14c",
          "grade": true,
          "grade_id": "cell-6c696e5279f751cc",
          "locked": true,
          "points": 30,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "for new_person_interview in new_people_interview:\n",
        "    for key in targets:\n",
        "        assert key in new_person_interview.keys()\n",
        "\n",
        "for new_person_hire in new_people_hire:\n",
        "    for key in targets:\n",
        "        assert key in new_person_hire.keys()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enVnHJUsIoso"
      },
      "source": [
        "### Ranking Evaluation\n",
        "\n",
        "Your manager notes that given that you might have more than one prediction target, the model predictions aren't really ranking or selecting people. There is no \"best\" person because there's more than one metric to look through. A human still needs to look through the predictions so your models don't yet really do what SellsALOT has asked for.\n",
        "\n",
        "Your manager asks you to create a synthetic scalar variable that is calculated from the multiple target predictions of an individual person. That way we'll have one metric by which we can rank people. You need to create that synthetic metric (score).\n",
        "\n",
        "Some candidate approaches:\n",
        "\n",
        "1. Incorporating a binary value, x:\n",
        "    - You can multiply x by some arbitrary value and add/subtract it to/from the total score:\n",
        "      - score = t1 + t2 * x\n",
        "    - You can multiple your entire score output by the binary value to say something like \"if not x, then  score is 0\", e.g.:\n",
        "      - score = x * (t1 + t2)\n",
        "1. Balancing between different target values:\n",
        "    - You can balance between different values by adding a multiplier (if t1 is twice as important as t2, then the score can be something like:\n",
        "     - score = 2 * t1 + t2\n",
        "1. Some combination of the items above\n",
        "1. Something creative you devise on your own!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "-PJoR68cInMi",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a20a434440cbaa8f2424bdc7bef7412d",
          "grade": false,
          "grade_id": "cell-d639d76def9446d0",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "def calculate_synthetic_metric(targets):\n",
        "    \"\"\"Calculates a synthetic matric based on the targets of an individual\n",
        "    Your metric should result in a higher score being a better one\n",
        "\n",
        "    Args:\n",
        "      targets (dict): The dictionary with keys as the target names and\n",
        "                      values as the target values/predictions\n",
        "\n",
        "    Returns:\n",
        "      float: The synthetic score produced from \n",
        "    \"\"\"\n",
        "\n",
        "    # in case someones df used a different name i.e., Fired_Fired vs Fired_Current Employee\n",
        "    cust_value = [value for key, value in targets.items() if 'customer satisfaction' in key.lower()][0]\n",
        "    sales_value = [value for key, value in targets.items() if 'sales' in key.lower()][0]\n",
        "    fired_value = [value for key, value in targets.items() if 'fired' in key.lower()][0]\n",
        "    return sales_value + 0.75*cust_value - 0.075*fired_value"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A658jUL-Kxpu"
      },
      "source": [
        "Let's try out the synthetic metric on the original data and see if you're happy with the result based on the past data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd04nSQFIQnM"
      },
      "source": [
        ""
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "RaTPe6B8Ksho",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1bdafa196b6b229524601ae3a2b95b56",
          "grade": false,
          "grade_id": "cell-3d6e8af884146387",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# Add a column named \"Metric\" to the **original** DataFrame with the synthetic metric applied to each row\n",
        "\n",
        "df['Metric'] = df[targets].apply(lambda x: calculate_synthetic_metric(x), axis=1)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "jztW-KZrIKSw",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2d8e68ef16698c391051af8b5507f0ed",
          "grade": true,
          "grade_id": "cell-bdb5b26a22302883",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "assert \"Metric\" in df.columns\n",
        "assert np.issubdtype(df[\"Metric\"].dtype, np.number)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy_LBAqeLQT0"
      },
      "source": [
        "Are you happy with the synthetic score based on the values for each person here? Go back and update it until you're satisfied with this score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "VaLgvQurLkjE",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "046aa4c11f5fc567707186a9649f0b39",
          "grade": true,
          "grade_id": "cell-25c42dc943a39e64",
          "locked": false,
          "points": 20,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# Explain the logic behind your synthetic scoring mechanism and save it as synthetic_score_reasoning\n",
        "\n",
        "synthetic_score_reasoning = \"\"\"I believe there should be more weight associated with the sales score. Even though the saying goes, 'the customer is always right',\n",
        "I believe it is more important for an employee to maintain a better sales score. Therefore, I decreased the weight of the customer score to 75%. For the fired binary\n",
        "variable I felt it needed to negatively impact the person if they have a fired response.\"\"\""
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "UlnqBpZUL1a8",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5fdf2191b11c7d91989b3e1aa9fc67f2",
          "grade": true,
          "grade_id": "cell-1fec797ad27734ef",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "assert len(synthetic_score_reasoning) > 100"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk-TMmydL7qn"
      },
      "source": [
        "Now let's calculate the synthetic scores for the new people (applicants) and see if you're satisfied with your models' rankings for interviewing and hiring."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eC4ydbKLPnk"
      },
      "source": [
        "new_people_interview_score = [calculate_synthetic_metric(target_values) for target_values in new_people_interview]\n",
        "new_people_hire_score = [calculate_synthetic_metric(target_values) for target_values in new_people_hire]"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHhfGnvTMh_T"
      },
      "source": [
        "best_interview_person = new_people[new_people_interview_score.index(max(new_people_interview_score))]\n",
        "best_hire_person = new_people[new_people_hire_score.index(max(new_people_hire_score))]"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nikv-vhUMi-z"
      },
      "source": [
        "Based on these scores, your model selected the following people:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEoWB0MGNFS-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b192720-5531-46b4-d3ba-cedc66224106"
      },
      "source": [
        "print(f\"\"\"\n",
        "Your interviewing model selected {best_interview_person['First Name']} {best_interview_person['Last Name']} as the person to interview.\n",
        "\n",
        "Your hiring model selected {best_hire_person['First Name']} {best_hire_person['Last Name']} as the person to hire.\n",
        "\"\"\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Your interviewing model selected Sarah Chang as the person to interview.\n",
            "\n",
            "Your hiring model selected Sarah Chang as the person to hire.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyEJR9axNmv_"
      },
      "source": [
        "Are you happy with these results? Feel free to modify the `applicant_5`'s attributes and see how your model performs based on changing these values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "FFWGYkmpNx_C",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3b544fd0fd911c789a56004c93fc3ac2",
          "grade": true,
          "grade_id": "cell-cc40d17ae80242e0",
          "locked": false,
          "points": 10,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ffec2a5-4af8-4c1a-d9e1-6f8a4d0a508c"
      },
      "source": [
        "# Describe your level of satisfaction with your models\n",
        "# Did you edit your model based on the results? What did you change?\n",
        "# What general conclusions did you get from the exercise\n",
        "# Save your answer to the above questions as conclusions\n",
        "\n",
        "conclusions = \"\"\"I am actually quite content with the way this turned out. It seems like theres a correlation between the variables that I believed would be most influential. I created what I felt would\n",
        "be a 'bad' applicant and even though they got through for an interview, the more strict hiring model classified them as fired...poor Billy Goat. Being a stats major, but not an avid Python user, I found this \n",
        "exercise very helpful with working with the pandas library as well as the regression and classification functions. Overall, this was an amazing summary of a lot of techniques we covered in this class. I liked\n",
        "that is wasn't so heavy on the end material, as some of that is still fresh. It allowed us to slowly work on it rather than being at a standstill.\"\"\"\n",
        "print(conclusions)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am actually quite content with the way this turned out. It seems like theres a correlation between the variables that I believed would be most influential. I created what I felt would\n",
            "be a 'bad' applicant and even though they got through for an interview, the more strict hiring model classified them as fired...poor Billy Goat. Being a stats major, but not an avid Python user, I found this \n",
            "exercise very helpful with working with the pandas library as well as the regression and classification functions. Overall, this was an amazing summary of a lot of techniques we covered in this class. I liked\n",
            "that is wasn't so heavy on the end material, as some of that is still fresh. It allowed us to slowly work on it rather than being at a standstill.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vBdn2XzOIhk"
      },
      "source": [
        "assert len(conclusions) > 100"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "aEDK4ChDQrky",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "03dcba3c87298cd428ec01f9a0075d6c",
          "grade": false,
          "grade_id": "cell-4a3caccc18c17350",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "## Feedback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "w-Yu33YPQrky",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "687d8bbd0750d67bdc439a0a539f4563",
          "grade": false,
          "grade_id": "cell-259e62fb9f936804",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "source": [
        "def feedback():\n",
        "    \"\"\"Provide feedback on the contents of this exercise\n",
        "    \n",
        "    Returns:\n",
        "        string\n",
        "    \"\"\"\n",
        "    return \"All good!\""
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnmMixrjJUql",
        "outputId": "d3d1f962-cc73-471a-9343-7871afd57149"
      },
      "source": [
        "print(feedback())"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All good!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}