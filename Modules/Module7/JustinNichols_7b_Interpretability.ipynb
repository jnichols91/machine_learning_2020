{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "JustinNichols_7b_Interpretability.ipynb",
      "private_outputs": true,
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6yC_ZDMM78t"
      },
      "source": [
        "## CSCI 470 Activities and Case Studies\n",
        "\n",
        "1. For all activities, you are allowed to collaborate with a partner. \n",
        "1. For case studies, you should work individually and are **not** allowed to collaborate.\n",
        "\n",
        "By filling out this notebook and submitting it, you acknowledge that you are aware of the above policies and are agreeing to comply with them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuSDCMD1M78t"
      },
      "source": [
        "Some considerations with regard to how these notebooks will be graded:\n",
        "\n",
        "1. You can add more notebook cells or edit existing notebook cells other than \"# YOUR CODE HERE\" to test out or debug your code. We actually highly recommend you do so to gain a better understanding of what is happening. However, during grading, **these changes are ignored**. \n",
        "2. You must ensure that all your code for the particular task is available in the cells that say \"# YOUR CODE HERE\"\n",
        "3. Every cell that says \"# YOUR CODE HERE\" is followed by a \"raise NotImplementedError\". You need to remove that line. During grading, if an error occurs then you will not receive points for your work in that section.\n",
        "4. If your code passes the \"assert\" statements, then no output will result. If your code fails the \"assert\" statements, you will get an \"AssertionError\". Getting an assertion error means you will not receive points for that particular task.\n",
        "5. If you edit the \"assert\" statements to make your code pass, they will still fail when they are graded since the \"assert\" statements will revert to the original. Make sure you don't edit the assert statements.\n",
        "6. We may sometimes have \"hidden\" tests for grading. This means that passing the visible \"assert\" statements is not sufficient. The \"assert\" statements are there as a guide but you need to make sure you understand what you're required to do and ensure that you are doing it correctly. Passing the visible tests is necessary but not sufficient to get the grade for that cell.\n",
        "7. When you are asked to define a function, make sure you **don't** use any variables outside of the parameters passed to the function. You can think of the parameters being passed to the function as a hint. Make sure you're using all of those variables.\n",
        "8. Finally, **make sure you run \"Kernel > Restart and Run All\"** and pass all the asserts before submitting. If you don't restart the kernel, there may be some code that you ran and deleted that is still being used and that was why your asserts were passing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZDe5fTqM78t"
      },
      "source": [
        "# Model Interpretability\n",
        "\n",
        "In this exercise you'll use the [alibi](https://docs.seldon.io/projects/alibi/en/stable/) library to explain why some models make the predictions they do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIbPnvTKM78u"
      },
      "source": [
        "! pip install alibi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjdHkCB0M78u"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3tEr4qcM78u"
      },
      "source": [
        "data = load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrNMA9hcM78u"
      },
      "source": [
        "print(data[\"DESCR\"])\n",
        "features = data[\"data\"]\n",
        "targets = data[\"target\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcR6WOLCM78u"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, targets, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LJj5D7tM78u"
      },
      "source": [
        "print(len(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b45cd198f4a64554f3690cdf9c7792c6",
          "grade": false,
          "grade_id": "cell-1a782646da471586",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "MBq0d-ZBM78u"
      },
      "source": [
        "## Create 2 classifiers: rf_clf that is a Random Forest model, and svm_clf that is a Linear SVM model\n",
        "## Train them both on the training data\n",
        "## Use them to predict the test data - saving it to y_rf_pred and y_svm_pred respectively\n",
        "## You may consider using GridSearchCV to determine a hyperparameter search for both models.\n",
        "\n",
        "rf_param_grid = {\n",
        "    'max_depth': [80, 90, 100],\n",
        "    'max_features': [2,3]\n",
        "}\n",
        "rf_grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=rf_param_grid, cv=5)\n",
        "rf_grid_search.fit(X_train, y_train)\n",
        "rf_clf = rf_grid_search.best_estimator_\n",
        "y_rf_pred = rf_clf.predict(X_test)\n",
        "\n",
        "svm_param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100, 1000]\n",
        "}\n",
        "svm_grid_search = GridSearchCV(estimator=LinearSVC(), param_grid=svm_param_grid, cv=5)\n",
        "svm_grid_search.fit(X_train, y_train)\n",
        "svm_clf = svm_grid_search.best_estimator_\n",
        "y_svm_pred = svm_clf.predict(X_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2327a90e98fdc548e354e54640fd9c5c",
          "grade": true,
          "grade_id": "cell-0591079d074b5029",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "E4rl6zgRM78u"
      },
      "source": [
        "assert len(y_rf_pred) == 38\n",
        "assert isinstance(rf_clf, RandomForestClassifier) or isinstance(rf_clf, GridSearchCV)\n",
        "assert len(y_svm_pred) == 38\n",
        "assert isinstance(svm_clf, LinearSVC) or isinstance(svm_clf, GridSearchCV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTw0mzHOM78u"
      },
      "source": [
        "print(f\"The random forest model achieved an accuracy of {accuracy_score(y_test, y_rf_pred)}.\")\n",
        "print(f\"The support vector machine model achieved an accuracy of {accuracy_score(y_test, y_svm_pred)}.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGbldGrFM78u"
      },
      "source": [
        "# Since we used a Linear SVM, we can easily determine the coefficients for the features:\n",
        "if isinstance(svm_clf, LinearSVC):\n",
        "    print(svm_clf.coef_)\n",
        "elif isinstance(svm_clf, GridSearchCV):\n",
        "    print(svm_clf.best_estimator_.coef_)\n",
        "\n",
        "print(\"Each class gets a coefficient for each feature that helps us determine that feature's importance.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CxwsyTZM78u"
      },
      "source": [
        "Now let's look at how we can use explainers, namely the [AnchorTabular](https://docs.seldon.io/projects/alibi/en/stable/methods/Anchors.html#id3) explainer to understand why the models make the predictions they do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QG_nmuBM78u"
      },
      "source": [
        "from alibi.explainers import AnchorTabular"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOIvjIrKM78u"
      },
      "source": [
        "Alibi explainers follow a general structure of:\n",
        "\n",
        "1. Initialize the explainer, providing a prediction function, and explainer specific parameters. `exp = Explainer(predict_func, param_1, param_2, ...)`\n",
        "1. Fit the explainer to the training data (this step is explainer dependent) `exp.fit(train_data)`\n",
        "1. Explain a given sample `exp.explain(sample)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0RqIVAIM78u"
      },
      "source": [
        "First, we reframe the prediction pipeline into a prediction function that we can use with the explainer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XitaEtdOM78u"
      },
      "source": [
        "rf_clf_func = lambda x: rf_clf.predict(x)\n",
        "svm_clf_func = lambda x: svm_clf.predict(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFrMD4uIM78u"
      },
      "source": [
        "Now we can instantiate the explainer using the prediction function and any parameters the explainer requires:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8o0O5xMM78u"
      },
      "source": [
        "rf_explainer = AnchorTabular(rf_clf_func, data[\"feature_names\"])\n",
        "rf_explainer.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJCTdcn2M78u"
      },
      "source": [
        "svm_explainer = AnchorTabular(svm_clf_func, data[\"feature_names\"])\n",
        "svm_explainer.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1CnlbukM78u"
      },
      "source": [
        "Once the explainer is set up, we can now use it to `.explain` samples! Pick a sample below to explain the two models' predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u2ZCym2M78u"
      },
      "source": [
        "# Change this value to choose a test sample\n",
        "index_to_explain = 5\n",
        "\n",
        "\n",
        "rf_explanation = rf_explainer.explain(X_test[index_to_explain])\n",
        "svm_explanation = svm_explainer.explain(X_test[index_to_explain])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJkzItVIM78u"
      },
      "source": [
        "rf_explanation.anchor, rf_explanation.precision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvkZIZijM78u"
      },
      "source": [
        "svm_explanation.anchor, svm_explanation.precision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_mxozeCM78u"
      },
      "source": [
        "Here we can see what the model's explanation for the classification of that sample is. You can see that even with our relatively interpretable model of Linear SVMs, these explainers can provide a more direct and intuitive explanation for why a sample was labeled the way it was.\n",
        "\n",
        "Now that you've seen the general approach for these explainers, let's work on something a bit more complex. Now you'll have to create the models, the prediction function, and the explainers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMxy1KDrM78u"
      },
      "source": [
        "## Explaining MNIST predictions\n",
        "\n",
        "Explaining data from measured observations is simple enough. Now let's try explaining how images get labeled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icswMM4EM78u"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrAubzWmM78u"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRFoFENWM78u"
      },
      "source": [
        "sample_index = 12\n",
        "sample = x_train[sample_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgPmkbOmM78u"
      },
      "source": [
        "plt.imshow(sample, cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ede0ab7718e54dbd9bd0656b3d195a55",
          "grade": false,
          "grade_id": "cell-0a1be97070f65961",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "VsBNtg3MM78u"
      },
      "source": [
        "## Create a neural network model that should do well on the MNIST dataset and save it to mnist_nn\n",
        "## Make the neural network sufficiently complex (at least 5 layers) and feel free to use Conv2D layers for example\n",
        "\n",
        "## Save the neural network to mnist_nn\n",
        "## You'll need to make sure you get at least 80% accuracy\n",
        "\n",
        "input_shape = x_train[0].reshape(28,28,1).shape\n",
        "layers = []\n",
        "layers.append(Conv2D(32, kernel_size=3, padding='same', activation ='relu', input_shape = input_shape))\n",
        "layers.append(MaxPool2D(padding='same'))\n",
        "layers.append(Conv2D(64, kernel_size=3, padding='same', activation ='relu'))\n",
        "layers.append(MaxPool2D(padding='same'))\n",
        "layers.append(Conv2D(128, kernel_size=3, padding='same', activation ='relu'))\n",
        "layers.append(MaxPool2D(padding='same'))\n",
        "layers.append(Conv2D(128, kernel_size=3, padding='same', activation ='relu'))\n",
        "layers.append(MaxPool2D(padding='same'))\n",
        "layers.append(Flatten())\n",
        "layers.append(Dense(100, activation='relu'))\n",
        "layers.append(Dense(100, activation='relu'))\n",
        "layers.append(Dense(10, activation='softmax'))\n",
        "mnist_nn = Sequential(layers)\n",
        "\n",
        "mnist_nn.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "mnist_nn.fit(x_train.reshape(-1, 28, 28 ,1), y_train, epochs=1)\n",
        "mnist_nn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "01b37abef0ca1da0df8c8f3f2b4025b2",
          "grade": true,
          "grade_id": "cell-e394a89e99cb2485",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "typAAmk8M78u"
      },
      "source": [
        "assert len(mnist_nn.layers) > 5\n",
        "assert mnist_nn.evaluate(x_test.reshape(-1, 28, 28 ,1), y_test)[1] > 0.8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhoTJQDKM78u"
      },
      "source": [
        "from alibi.explainers import AnchorImage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByN8Jk52M78v"
      },
      "source": [
        "To work with images, we'll use the [AnchorImage](https://docs.seldon.io/projects/alibi/en/stable/methods/Anchors.html#id5) explainer. This explainer requires that we break up the image into \"superpixels\". We'll use the function in the next cell to do just that. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFqGuUNSM78v"
      },
      "source": [
        "def superpixel(image, size=(4, 4)):\n",
        "    segments = np.zeros([image.shape[0], image.shape[1]])\n",
        "    row_idx, col_idx = np.where(segments == 0)\n",
        "    for i, j in zip(row_idx, col_idx):\n",
        "        segments[i, j] = int((image.shape[1]/size[1]) * (i//size[0]) + j//size[1])\n",
        "    return segments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk6lEUIcM78v"
      },
      "source": [
        "segments = superpixel(x_train[0])\n",
        "plt.imshow(segments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9iRFr23M78v"
      },
      "source": [
        "Each presented square is a superpixel. You can change the code above to test out other ways of determining superpixels. You could even just simply change the size from 4,4 to a different size and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cbd424c67b4f3c7e21b06bc6d9b12a5f",
          "grade": false,
          "grade_id": "cell-2b6099964aa0a2be",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "-3iOeYAaM78v"
      },
      "source": [
        "# Create an explainer object using AnchorImage that explains the mnist_nn model you created.\n",
        "# Make sure to use the superpixel function as the segmentation function \n",
        "\n",
        "predict_fn = lambda x: mnist_nn.predict(x)\n",
        "mnist_explainer = AnchorImage(predict_fn, input_shape, segmentation_fn=superpixel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "492e1773d0063d2a1a2f8a2ed1f49592",
          "grade": true,
          "grade_id": "cell-f81be29970fdaf29",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0pQKfNxyM78v"
      },
      "source": [
        "assert isinstance(mnist_explainer, AnchorImage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kd_NCzJM78v"
      },
      "source": [
        "# Change this number and try out different samples\n",
        "image_index_to_explain = 2\n",
        "image_to_explain = x_test.reshape(-1, 28, 28 ,1)[image_index_to_explain]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eX9U0GHM78v"
      },
      "source": [
        "plt.imshow(image_to_explain[:,:,0], cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwjcjepxM78v"
      },
      "source": [
        "# Change the value of p_sample, and threshold here to see how the explanation changes based on the sample.\n",
        "mnist_image_explanation = mnist_explainer.explain(image_to_explain, threshold=.9, p_sample=.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaaE_a0QM78v"
      },
      "source": [
        "print(f\"The model predicted the number as a {mnist_nn.predict(image_to_explain.reshape(1, 28, 28, 1)).argmax()} because of:\")\n",
        "plt.imshow(mnist_image_explanation.anchor[:,:,0], cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p020cN5iM78v"
      },
      "source": [
        "One thing you may have noticed is that the explanations are heavily dependent on the superpixels we identify. Have ideas for a better superpixel definition? Go back and try it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fu480tfM78v"
      },
      "source": [
        "## Explaining newsgroup predictions\n",
        "\n",
        "With the newsgroup dataset we'll look at explaining how text gets predicted using [AnchorText](https://docs.seldon.io/projects/alibi/en/v0.2.2/methods/Anchors.html#Initialization)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiP6mDXbM78v"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import spacy\n",
        "from alibi.explainers import AnchorText\n",
        "from alibi.utils.download import spacy_model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS-4XVdLM78v"
      },
      "source": [
        "newsgroups = fetch_20newsgroups()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRA_c96qM78v"
      },
      "source": [
        "print(newsgroups[\"DESCR\"])\n",
        "text = newsgroups[\"data\"]\n",
        "news_labels = newsgroups[\"target\"]\n",
        "newsgroup_names = newsgroups[\"target_names\"]\n",
        "\n",
        "text_train, text_test, labels_train, labels_test = train_test_split(text, news_labels, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoK4GQT-M78v"
      },
      "source": [
        "# Creating a TFIDF vectorizer and Linear SVM classifier to make predictions about the newsgroup dataset\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf.fit(text_train)\n",
        "\n",
        "clf = LinearSVC()\n",
        "clf.fit(tfidf.transform(text_train), labels_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c38e085a0f04503420ab1c4d3e804f3d",
          "grade": false,
          "grade_id": "cell-9328ed37549d0d6c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "-FJTZ5FeM78v"
      },
      "source": [
        "# Create newsgroup_predictor which is a predictor function to use with an AnchorText predictor using\n",
        "# the vectorizer and classifier defined in the cell above\n",
        "# Note that you have to transform the data with the vectorizer and then predict it.\n",
        "\n",
        "newsgroup_predictor = lambda x: clf.predict(tfidf.transform(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "67f9943d90704e2342af4565b08ca501",
          "grade": true,
          "grade_id": "cell-f5ed32ccd8efa182",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ao34NypKM78v"
      },
      "source": [
        "assert len(newsgroup_predictor(text_test[:2])) == 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1gu6GdsM78v"
      },
      "source": [
        "model = 'en_core_web_md'\n",
        "spacy_model(model=model)\n",
        "nlp = spacy.load(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZFfoyk0M78v"
      },
      "source": [
        "# Create the explainer to use\n",
        "newsgroup_explainer = AnchorText(nlp, newsgroup_predictor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a974c89bfd3e84c2ecdccc4fa0fd6cc4",
          "grade": false,
          "grade_id": "cell-57dc731897b7b73a",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "WYIqFzCvM78v"
      },
      "source": [
        "# Copy the text of an article you find on the internet and save it as article\n",
        "\n",
        "article = \"\"\"Sprinting through the office door and leaping onto his stunned father’s lap, 27-year-old Dennis Radomir loudly announced Daddy, I’m hungry Monday as he burst into the background of a work-related video conference. \n",
        "Daddy, Daddy, my tummy is grumbling, please can I have my yum yums now, whined the fully grown adult male before taking off his shirt, falling to the ground, and crying loudly after his father refused to give him his favorite \n",
        "dino nuggies. Sprinting through the office door and leaping onto his stunned father’s lap, 27-year-old Dennis Radomir loudly announced Daddy, I’m hungry Monday as he burst into the background of a work-related video conference.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "df107c35762a3a1b35781cf14f5e45b6",
          "grade": true,
          "grade_id": "cell-501e6db67729a04d",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "_7VTmAmlM78v"
      },
      "source": [
        "assert len(article) > 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2524df710c7c0101f986a026d004aadc",
          "grade": false,
          "grade_id": "cell-24c6bbba046e8fd4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "tEq0WclNM78v"
      },
      "source": [
        "# Define article_explanation as the explainer's explanation for the article you provided.\n",
        "\n",
        "article_explanation = newsgroup_explainer.explain(article)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q2OUfY1M78v"
      },
      "source": [
        "print(f\"The model predicted the article as {newsgroup_names[newsgroup_predictor([article])[0]]} because of the word: {article_explanation.anchor}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbhT_3flM78v"
      },
      "source": [
        "# Change this number and try out different samples\n",
        "test_sample_index = 28\n",
        "test_sample = text_test[test_sample_index]\n",
        "print(test_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QHh0ZZwM78v"
      },
      "source": [
        "test_sample_explanation = newsgroup_explainer.explain(test_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HogDn7bSM78v"
      },
      "source": [
        "print(f\"The model predicted the test sample as {newsgroup_names[newsgroup_predictor([test_sample])[0]]} because of the word {test_sample_explanation.anchor}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13oRbqVJM78v"
      },
      "source": [
        "## Feedback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6ff0d8bed14ed80b45c8ae821e8967e6",
          "grade": false,
          "grade_id": "cell-523ebab8f9ab57b8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "MV09iGpJM78v"
      },
      "source": [
        "def feedback():\n",
        "    \"\"\"Provide feedback on the contents of this exercise\n",
        "    \n",
        "    Returns:\n",
        "        string\n",
        "    \"\"\"\n",
        "    return \"Other than not getting a chance to see if the article worked, all good!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7kXw8O_M78v"
      },
      "source": [
        "print(feedback())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}