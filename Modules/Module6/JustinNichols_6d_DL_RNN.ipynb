{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "JustinNichols_6d_DL_RNN.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Ylsv3tPSr-"
      },
      "source": [
        "## CSCI 470 Activities and Case Studies\n",
        "\n",
        "1. For all activities, you are allowed to collaborate with a partner. \n",
        "1. For case studies, you should work individually and are **not** allowed to collaborate.\n",
        "\n",
        "By filling out this notebook and submitting it, you acknowledge that you are aware of the above policies and are agreeing to comply with them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01-T6smjPSr_"
      },
      "source": [
        "Some considerations with regard to how these notebooks will be graded:\n",
        "\n",
        "1. You can add more notebook cells or edit existing notebook cells other than \"# YOUR CODE HERE\" to test out or debug your code. We actually highly recommend you do so to gain a better understanding of what is happening. However, during grading, **these changes are ignored**. \n",
        "2. You must ensure that all your code for the particular task is available in the cells that say \"# YOUR CODE HERE\"\n",
        "3. Every cell that says \"# YOUR CODE HERE\" is followed by a \"raise NotImplementedError\". You need to remove that line. During grading, if an error occurs then you will not receive points for your work in that section.\n",
        "4. If your code passes the \"assert\" statements, then no output will result. If your code fails the \"assert\" statements, you will get an \"AssertionError\". Getting an assertion error means you will not receive points for that particular task.\n",
        "5. If you edit the \"assert\" statements to make your code pass, they will still fail when they are graded since the \"assert\" statements will revert to the original. Make sure you don't edit the assert statements.\n",
        "6. We may sometimes have \"hidden\" tests for grading. This means that passing the visible \"assert\" statements is not sufficient. The \"assert\" statements are there as a guide but you need to make sure you understand what you're required to do and ensure that you are doing it correctly. Passing the visible tests is necessary but not sufficient to get the grade for that cell.\n",
        "7. When you are asked to define a function, make sure you **don't** use any variables outside of the parameters passed to the function. You can think of the parameters being passed to the function as a hint. Make sure you're using all of those variables.\n",
        "8. Finally, **make sure you run \"Kernel > Restart and Run All\"** and pass all the asserts before submitting. If you don't restart the kernel, there may be some code that you ran and deleted that is still being used and that was why your asserts were passing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "148a186cdc339d18c6a3c0bf33ad5a6e",
          "grade": false,
          "grade_id": "cell-d07e9bbbd9efabf6",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "glCWjLxUPSr_"
      },
      "source": [
        "# Deep Learning - Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "df48be318c20412564ef812c320d2510",
          "grade": false,
          "grade_id": "cell-aaad388f467a51c0",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "wv7SsrwuPSsA"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import SimpleRNN, GRU, LSTM, Embedding, Dense\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a7317042415be1e532b31c2cc056d9fa",
          "grade": false,
          "grade_id": "cell-bda9bc8e1d0c997d",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "cVSkE9_4PSsD"
      },
      "source": [
        "We will be using the IMDB dataset outlined in the keras documentation [here](https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification). We will be applying a supervised learning application to text where we predict the sentiment of the IMDB reviews.\n",
        "\n",
        "Take a look at the imports above. For the RNN based imports see the [RNN documentation](https://keras.io/layers/recurrent). For preprocessing using `sequence` see the [sequence documentation](https://keras.io/preprocessing/sequence). For Embedding, see the [Embedding documentation](https://keras.io/layers/embeddings/).\n",
        "\n",
        "From the Keras documentation, linked above:\n",
        ">\"This is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a list of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "257838f74061ae830d9d6f55eabd08ed",
          "grade": false,
          "grade_id": "cell-c5683134993794d6",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "RqfKQITYPSsD"
      },
      "source": [
        "maxlen = 100 # Only use sentences up to this many words\n",
        "n = 20000 # Only use the most frequent n words\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=n)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c7c4a5c23bee6c65b41a116d5dcaf6c7",
          "grade": false,
          "grade_id": "cell-2d04aa072205ee4a",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "CRl8OEvXPSsF",
        "outputId": "ec6f50ae-1ac3-425b-cb16-c2aaec233fa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a4c3388aacf1d735a644960c64697ef8",
          "grade": false,
          "grade_id": "cell-c69f7bd45588c10f",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "fC0r-e-pPSsH",
        "outputId": "185d68b6-7d75-47b4-e181-a1622691308b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b123c8981fb62ef850e3f8921796d5c0",
          "grade": false,
          "grade_id": "cell-59607cac09a99a93",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "FQxbD_25PSsJ",
        "outputId": "c123f7c8-eea4-4cb1-8a4c-ac2b562f9de1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(10):\n",
        "    print(f\"Element {i} has a length of {len(x_train[i])}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Element 0 has a length of 218\n",
            "Element 1 has a length of 189\n",
            "Element 2 has a length of 141\n",
            "Element 3 has a length of 550\n",
            "Element 4 has a length of 147\n",
            "Element 5 has a length of 43\n",
            "Element 6 has a length of 123\n",
            "Element 7 has a length of 562\n",
            "Element 8 has a length of 233\n",
            "Element 9 has a length of 130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "25138d378e0de2c56acc6fc7c8a80cce",
          "grade": false,
          "grade_id": "cell-9d17ff409cf0ed6a",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "nXVJnuPaPSsL",
        "outputId": "8d8f69e3-4967-43aa-cb76-2343f1c56d9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train[0][:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f01af8b921e7219a1d6496f80022e99e",
          "grade": false,
          "grade_id": "cell-29008f854c9ed905",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "WnF80H8iPSsN"
      },
      "source": [
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ce4ea6cd24d56fdd9e3646d504c1638b",
          "grade": false,
          "grade_id": "cell-26b3b6b877561751",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "QekuwrxfPSsP",
        "outputId": "b00dde87-234b-4d09-dae5-78d4961cb1eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 100), (25000, 100))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "eb0658983557cfc6d5d749c18d5c3a08",
          "grade": false,
          "grade_id": "cell-80d546e03cc3a91a",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "PdHHqUDDPSsR"
      },
      "source": [
        "Each data sample is a sequence of integers that represent the index of the word in our vocabulary. This saves on storage when compared to a vector that's as long as our vocabulary with all 0's and just one 1 as discussed in the lecture. We will be using the [Embedding layer](https://keras.io/layers/embeddings/) to adapt this for our neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2793d772ae01513635a946f32a65d908",
          "grade": false,
          "grade_id": "cell-9c1b0c9c7d26e3fc",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "VfzATQ2jPSsR",
        "outputId": "9de219f2-25dd-4937-a38d-66eda18e4db8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"All values of the targets are integers with the following max and min values\")\n",
        "print(f\"{y_train.max()}, {y_train.min()}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All values of the targets are integers with the following max and min values\n",
            "1, 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0346e2170feadaf176a0c0d32ccb8513",
          "grade": false,
          "grade_id": "cell-a96be599550f72f2",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "V0UFT7tjPSsT"
      },
      "source": [
        "We will build three networks, using basic RNNs, GRUs and LSTMs. We will then compare their performance in predicting the classes of reviews appropriately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4e1a8a9f06ee330c7df4d7882b5d8130",
          "grade": false,
          "grade_id": "cell-89247ca5db4b603e",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "PZI-9v93PSsT"
      },
      "source": [
        "# Define \"simple_layers\", a list of Keras layers, that you will then use to create a Sequential model\n",
        "# saved as \"my_simple\".\n",
        "# \n",
        "# Here you will create a simple RNN using one SimpleRNN layer with dropout and recurrent_dropout\n",
        "# (see argument options in SimpleRNN documentation).\n",
        "# \n",
        "# You will need to use an Embedding layer as the first layer (to convert the data appropriately)\n",
        "# followed by the SimpleRNN layer. Select an embedding size of your choice, and use that for your\n",
        "# SimpleRNN layer's output dimensions as well.\n",
        "#\n",
        "# Finally, create an output layer that applies to our dataset task of binary classification\n",
        "\n",
        "simple_layers = []\n",
        "simple_layers.append(Embedding(input_dim=n, output_dim=128, input_length=maxlen))\n",
        "simple_layers.append(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.5))\n",
        "simple_layers.append(Dense(1, activation='sigmoid'))\n",
        "my_simple = Sequential(simple_layers)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0a8cf4a1554786648cfb1318f2bc79dc",
          "grade": true,
          "grade_id": "cell-a693cb84784a5e8d",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false
        },
        "id": "ns1A0vKhPSsV"
      },
      "source": [
        "assert len(simple_layers) == 3\n",
        "assert isinstance(simple_layers[0], Embedding)\n",
        "assert isinstance(simple_layers[1], SimpleRNN)\n",
        "assert isinstance(simple_layers[2], Dense)\n",
        "assert simple_layers[0].output_dim == simple_layers[1].units\n",
        "assert simple_layers[1].dropout > 0\n",
        "assert simple_layers[1].recurrent_dropout > 0\n",
        "assert my_simple"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8d73657260a770b1f13296effcaa37d9",
          "grade": false,
          "grade_id": "cell-10a0d33cc462aa67",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "LzVAJbYGPSsX",
        "outputId": "486ee45c-d694-4509-978a-c52bcda9e7b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "my_simple.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "my_simple.fit(x_train, y_train, batch_size=32, epochs=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 74s 95ms/step - loss: 0.7283 - accuracy: 0.5016\n",
            "CPU times: user 2min 1s, sys: 5.78 s, total: 2min 7s\n",
            "Wall time: 1min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a588817120cfc85fdc1281fdb99a05ee",
          "grade": false,
          "grade_id": "cell-9b7b7778053b0aa3",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "JP7l-XXWPSsZ"
      },
      "source": [
        "# Define \"gru_layers\", a list of Keras layers, that you will then use to create a Sequential model\n",
        "# saved as \"my_gru\".\n",
        "#\n",
        "# Here you will create an RNN using a GRU layer, with dropout and recurrent_dropout.\n",
        "#\n",
        "# Use an input Embedding layer and output Dense layer, as in the simple RNN model.\n",
        "\n",
        "gru_layers = []\n",
        "gru_layers.append(Embedding(input_dim=n, output_dim=128, input_length=maxlen))\n",
        "gru_layers.append(GRU(128, dropout=0.2, recurrent_dropout=0.5))\n",
        "gru_layers.append(Dense(1, activation='sigmoid'))\n",
        "my_gru = Sequential(gru_layers)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4f9a717049b8744e9490f324fba1fc24",
          "grade": true,
          "grade_id": "cell-c69132493de5ac88",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false
        },
        "id": "zJsfd8jKPSsb"
      },
      "source": [
        "assert len(gru_layers) == 3\n",
        "assert isinstance(gru_layers[0], Embedding)\n",
        "assert isinstance(gru_layers[1], GRU)\n",
        "assert isinstance(gru_layers[2], Dense)\n",
        "assert gru_layers[0].output_dim == gru_layers[1].units\n",
        "assert gru_layers[1].dropout > 0\n",
        "assert gru_layers[1].recurrent_dropout > 0\n",
        "assert my_gru"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3f8a2793b9cf15063bcafef69ea11131",
          "grade": false,
          "grade_id": "cell-5c71db6dcb81eb2a",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "T3GZwWhtPSsc",
        "outputId": "68ecde3e-2ee4-4cb1-f59b-5c9ee04b7a2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "my_gru.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "my_gru.fit(x_train, y_train, batch_size=32, epochs=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 219s 280ms/step - loss: 0.4465 - accuracy: 0.7833\n",
            "CPU times: user 6min 34s, sys: 18.7 s, total: 6min 53s\n",
            "Wall time: 3min 41s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "074f031adaafa55dbb69945cc42d9e40",
          "grade": false,
          "grade_id": "cell-798617aedf043516",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "n6xVpc2hPSse"
      },
      "source": [
        "# Define \"lstm_layers\", a list of Keras layers, that you will then use to create a Sequential model\n",
        "# saved as \"my_lstm\".\n",
        "#\n",
        "# Here you will create an RNN using an LSTM layer, again, with dropout and recurrent_dropout.\n",
        "#\n",
        "# Use an input Embedding layer and output Dense layer, as in the simple RNN and the GRU model.\n",
        "\n",
        "lstm_layers = []\n",
        "lstm_layers.append(Embedding(input_dim=n, output_dim=128, input_length=maxlen))\n",
        "lstm_layers.append(LSTM(128, dropout=0.2, recurrent_dropout=0.5))\n",
        "lstm_layers.append(Dense(1, activation='sigmoid'))\n",
        "my_lstm = Sequential(lstm_layers)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1a0e568fe8c02d9e8ae681db979b4886",
          "grade": true,
          "grade_id": "cell-58a52ce9bceabdee",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false
        },
        "id": "PyRD5yE4PSsg"
      },
      "source": [
        "assert len(lstm_layers) == 3\n",
        "assert isinstance(lstm_layers[0], Embedding)\n",
        "assert isinstance(lstm_layers[1], LSTM)\n",
        "assert isinstance(lstm_layers[2], Dense)\n",
        "assert lstm_layers[0].output_dim == lstm_layers[1].units\n",
        "assert lstm_layers[1].dropout > 0\n",
        "assert lstm_layers[1].recurrent_dropout > 0\n",
        "assert my_lstm"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "64f5b9ef67549c3ccdd52cf22907a0ed",
          "grade": false,
          "grade_id": "cell-33238b0da6c68f44",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "99NHF9uuPSsi",
        "outputId": "7d1d2277-fd58-40e9-d7bc-ae60a05bd491",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "my_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "my_lstm.fit(x_train, y_train, batch_size=32, epochs=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 242s 310ms/step - loss: 0.4195 - accuracy: 0.8032\n",
            "CPU times: user 7min 8s, sys: 30.8 s, total: 7min 39s\n",
            "Wall time: 4min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "06da7d2df6c07981e56afc9151b0f5ad",
          "grade": false,
          "grade_id": "cell-43b2247e569276bc",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "UJNdpXWpPSsl",
        "outputId": "3af87a7f-300e-43db-ad9f-8a680513a6ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate your models on the test set and save the loss and accuracies to the appropriate variables:\n",
        "# model_name_loss, model_name_acc (e.g., my_simple_loss and my_simple_acc).\n",
        "\n",
        "my_simple_loss, my_simple_acc = my_simple.evaluate(x_test, y_test)\n",
        "my_gru_loss, my_gru_acc = my_gru.evaluate(x_test, y_test)\n",
        "my_lstm_loss, my_lstm_acc = my_lstm.evaluate(x_test, y_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 10s 12ms/step - loss: 0.6932 - accuracy: 0.5119\n",
            "782/782 [==============================] - 23s 29ms/step - loss: 0.3480 - accuracy: 0.8496\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 0.4088 - accuracy: 0.8129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a0a15ab1242ee6a422212cdf05c096d1",
          "grade": false,
          "grade_id": "cell-24347394026d518c",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "kWl8U5bOPSsm",
        "outputId": "e8705ca1-52dc-484e-8c03-9c210c436583",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"Your simple model achieved an accuracy of {my_simple_acc:.2}.\")\n",
        "print(f\"Your GRU model achieved an accuracy of {my_gru_acc:.2}.\")\n",
        "print(f\"Your LSTM model achieved an accuracy of {my_lstm_acc:.2}.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your simple model achieved an accuracy of 0.51.\n",
            "Your GRU model achieved an accuracy of 0.85.\n",
            "Your LSTM model achieved an accuracy of 0.81.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3426ed141c7ecdfcb8765e570940a3de",
          "grade": false,
          "grade_id": "cell-95c1830b360ac2b2",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "cScJ82CNPSso"
      },
      "source": [
        "Note that we are only running these models with 1 layer and training them for only 1 epoch. We can easily achieve better results by stacking multiple layers but the model would take a much longer time to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d09aaaa2e38735c05865905d77323d90",
          "grade": true,
          "grade_id": "cell-3e1e2805ce275b4c",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false
        },
        "id": "EYAtW_NzPSso"
      },
      "source": [
        "assert my_simple_acc > 0.4\n",
        "assert my_gru_acc > 0.6\n",
        "assert my_lstm_acc > 0.7"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "830573f46459d11e5238532d8759463e",
          "grade": false,
          "grade_id": "cell-bc503c7f94e3b8bf",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "nTTK8bXePSsp"
      },
      "source": [
        "## Feedback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ed936ab53a1391c5e6af8df699a1dbf5",
          "grade": false,
          "grade_id": "feedback",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "YgjmAWdLPSsq"
      },
      "source": [
        "def feedback():\n",
        "    \"\"\"Provide feedback on the contents of this exercise\n",
        "    \n",
        "    Returns:\n",
        "        string\n",
        "    \"\"\"\n",
        "    return \"All good!\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f39f6185a54850c2f1f9b5b2a17b7543",
          "grade": true,
          "grade_id": "feedback-tests",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false
        },
        "id": "xKa_7OOyPSsr",
        "outputId": "2b1f49c9-2433-449f-d3bd-c3f81a676203",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(feedback())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All good!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}