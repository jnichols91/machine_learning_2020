{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "JustinNichols_3d_UL_Density_Estimation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhSAattBBthh"
      },
      "source": [
        "## CSCI 470 Activities and Case Studies\n",
        "\n",
        "1. For all activities, you are allowed to collaborate with a partner. \n",
        "1. For case studies, you should work individually and are **not** allowed to collaborate.\n",
        "\n",
        "By filling out this notebook and submitting it, you acknowledge that you are aware of the above policies and are agreeing to comply with them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1JGd6KDBthh"
      },
      "source": [
        "Some considerations with regard to how these notebooks will be graded:\n",
        "\n",
        "1. You can add more notebook cells or edit existing notebook cells other than \"# YOUR CODE HERE\" to test out or debug your code. We actually highly recommend you do so to gain a better understanding of what is happening. However, during grading, **these changes are ignored**. \n",
        "2. You must ensure that all your code for the particular task is available in the cells that say \"# YOUR CODE HERE\"\n",
        "3. Every cell that says \"# YOUR CODE HERE\" is followed by a \"raise NotImplementedError\". You need to remove that line. During grading, if an error occurs then you will not receive points for your work in that section.\n",
        "4. If your code passes the \"assert\" statements, then no output will result. If your code fails the \"assert\" statements, you will get an \"AssertionError\". Getting an assertion error means you will not receive points for that particular task.\n",
        "5. If you edit the \"assert\" statements to make your code pass, they will still fail when they are graded since the \"assert\" statements will revert to the original. Make sure you don't edit the assert statements.\n",
        "6. We may sometimes have \"hidden\" tests for grading. This means that passing the visible \"assert\" statements is not sufficient. The \"assert\" statements are there as a guide but you need to make sure you understand what you're required to do and ensure that you are doing it correctly. Passing the visible tests is necessary but not sufficient to get the grade for that cell.\n",
        "7. When you are asked to define a function, make sure you **don't** use any variables outside of the parameters passed to the function. You can think of the parameters being passed to the function as a hint. Make sure you're using all of those variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "33495dc70b269f4040bbecb9b1135ce2",
          "grade": false,
          "grade_id": "cell-c2a67d718e5cbe74",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "dSYebzfEBthi"
      },
      "source": [
        "# Unsupervised Learning - Density Estimation\n",
        "\n",
        "In this exercise we'll focus on learning about histograms and how choosing the bin count changes the histogram that is created. From there, we'll look at how changing the density estimation function and its hyperparameters results in better or worse fits to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "263e06df490f9fbfc95c594c76d78d7d",
          "grade": false,
          "grade_id": "cell-c3aced8ff424c31b",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "PzxBDUYMBthj"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn as sk\n",
        "import math\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "18ace3a7c284ad1fb3863e42138caccf",
          "grade": false,
          "grade_id": "cell-3c0ed12f0ba926be",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "RBTXCwGwBthm"
      },
      "source": [
        "from sklearn.neighbors import KernelDensity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6ac7408b67f662456c0c6eb5b83ea096",
          "grade": false,
          "grade_id": "cell-b3fb0a4efb6f9a9b",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "cNaB6isyBtho"
      },
      "source": [
        "mu_1, sigma_1, n_1 = 0, 0.5, 1000\n",
        "mu_2, sigma_2, n_2 = 2, 1, 500\n",
        "\n",
        "vals_1 = np.random.normal(mu_1, sigma_1, n_1)\n",
        "vals_2 = np.random.normal(mu_2, sigma_2, n_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ccb30f677890d4f62d922ea5e2d36de2",
          "grade": false,
          "grade_id": "cell-bd3d02740dcaf515",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "3TTGjOZ2Bthq"
      },
      "source": [
        "vals = np.concatenate((vals_1, vals_2), axis=0)\n",
        "n = vals.shape[0]\n",
        "sigma = vals.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c998c496ba50bc7b773e675894fd6a63",
          "grade": false,
          "grade_id": "cell-4c9549a418314408",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "_95ct5FMBtht"
      },
      "source": [
        "plt.hist(vals, 10)\n",
        "plt.title(\"Potentially Misleading Histogram\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "caa6ba369f64ea9c84f9b08ed45fd88f",
          "grade": false,
          "grade_id": "cell-1b2b7bf13f0fcbe8",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "4QKFmSfVBthv"
      },
      "source": [
        "n, sigma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bb76d6c96607d74336faa45e75127ce3",
          "grade": false,
          "grade_id": "cell-0d06a3a983734f30",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "iSNAMGiKBthx"
      },
      "source": [
        "We can calculate the number of bins, $b$, from the bin width, $w$, as\n",
        "$$\n",
        "b = \\frac{max - min}{w}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "30ffa108db2b08a7ee83c0c1a80c34bd",
          "grade": false,
          "grade_id": "cell-910b2fec64f1b3ee",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "NRY9RJqzBthy"
      },
      "source": [
        "def bin_count(max_val, min_val, width):\n",
        "    \"\"\"Return the number of bins for a histogram\n",
        "    \n",
        "    Args:\n",
        "        max_val (float): The maximum value in the dataset\n",
        "        min_val (float): The minimum value in the dataset\n",
        "        width (float): The bin width\n",
        "    \n",
        "    Returns:\n",
        "        int: The number of bins for the histogram\n",
        "    \"\"\"\n",
        "    return math.ceil((max_val - min_val) / width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cbca6aa9137104c48825d8f5b59b61e5",
          "grade": true,
          "grade_id": "cell-9123d41096ad1ee0",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false
        },
        "id": "IQ9h4rvZBth0"
      },
      "source": [
        "assert bin_count(500, 100, 20) == 20\n",
        "assert bin_count(600, 100, 25) == 20\n",
        "assert bin_count(500, 100, 18) == 23\n",
        "assert isinstance(bin_count(500, 100, 20), int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4ef24fbf7df204f50d6b41473e19c056",
          "grade": false,
          "grade_id": "cell-d065e8def62a51a3",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "DzJVPf2cBth2"
      },
      "source": [
        "Now let's select a better number of bins by using Scott's rule and Freedman & Diaconis' rule."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f3b6fd156889f1907a1f14eeef79ef97",
          "grade": false,
          "grade_id": "cell-25968153c0682214",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "8t3TSkg8Bth2"
      },
      "source": [
        "def scotts_rule_count(data):\n",
        "    \"\"\"Calculate the number of bins using Scott's rule\n",
        "    \n",
        "    Args:\n",
        "        data (np.ndarray): The data array\n",
        "    \n",
        "    Returns:\n",
        "        int: The number of bins of the histogram\n",
        "    \"\"\"\n",
        "    scott_width = 3.49*data.std()*data.shape[0]**(-1/3)\n",
        "    return bin_count(max(data), min(data), scott_width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b2f443a7fd3f5fa6929b43d55504e561",
          "grade": true,
          "grade_id": "cell-b9b4813b01b4ece6",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false
        },
        "id": "joKEBlPABth4"
      },
      "source": [
        "test_data = np.random.normal(0,1,500)\n",
        "test_data_2 = np.random.uniform(0,5,500)\n",
        "assert isinstance(scotts_rule_count(np.random.normal(0,1,500)), int)\n",
        "assert scotts_rule_count(test_data) in (13,14,15)\n",
        "assert scotts_rule_count(test_data_2) in (8,9,10)\n",
        "sigma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "95028acaa9ee1a9d1b5aa51664e219b3",
          "grade": false,
          "grade_id": "cell-d8d88b571e823a16",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "M4mvkcWdBth8"
      },
      "source": [
        "scott_bins = scotts_rule_count(vals)\n",
        "print(f\"Creating a histogram with {scott_bins} bins.\")\n",
        "plt.hist(vals, bins=scott_bins)\n",
        "plt.title(\"Scott's Rule Histogram\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7f362aad5f62a47b9acb690c772a3dbb",
          "grade": false,
          "grade_id": "cell-eb7a054a424b306a",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "1e8_siodBth-"
      },
      "source": [
        "Now we'll try Freedman and Diaconis' rule. To calculate the interquartile range, you may want to look into calculating the percentiles using [np.percentile](https://docs.scipy.org/doc/numpy/reference/generated/numpy.percentile.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "62c2ca5f58acd9da3d45dcb67b5d296c",
          "grade": false,
          "grade_id": "cell-9213476e5ce4a45d",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "CDCPLzpIBth_"
      },
      "source": [
        "def fd_rule_count(data):\n",
        "    \"\"\"Calculate the number of bins using Freedman & Diaconis' rule\n",
        "    \n",
        "    Args:\n",
        "        data (np.ndarray): The data array\n",
        "    \n",
        "    Returns:\n",
        "        int: The number of bins for the histogram\n",
        "    \"\"\"\n",
        "    per = np.percentile(data, [25, 75])\n",
        "    d = per[1] - per[0]\n",
        "    FD_width = 2*d*data.shape[0]**(-1/3)\n",
        "    return bin_count(max(data), min(data), FD_width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1b6013377d923c4992ffdcefd701fda5",
          "grade": true,
          "grade_id": "cell-a6359eff72ee4b15",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false
        },
        "id": "r-_tYal7BtiB"
      },
      "source": [
        "assert fd_rule_count(test_data) in (15,16,17)\n",
        "assert fd_rule_count(test_data_2) in (8,9,10)\n",
        "assert isinstance(fd_rule_count(test_data), int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ecc65d4bdd3c107c03a3806005fc3666",
          "grade": false,
          "grade_id": "cell-5264c19f0cbfaaa8",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "wMeybpBaBtiD"
      },
      "source": [
        "fd_bins = fd_rule_count(vals)\n",
        "print(f\"Creating a histogram with {fd_bins} bins.\")\n",
        "plt.hist(vals, bins=fd_bins)\n",
        "plt.title(\"Freedman & Diaconis' Rule Histogram\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d7f5bcb0677c5128202e46851540dc81",
          "grade": false,
          "grade_id": "cell-92e34c320aba9996",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "DlqlDfN3BtiF"
      },
      "source": [
        "## Kernel Density Estimation\n",
        "\n",
        "Let's add a density estimate to the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b2440ea16d548cdae571cef2616b3406",
          "grade": false,
          "grade_id": "cell-4df0f2362e27f5c4",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "zjliFGxRBtiF"
      },
      "source": [
        "def kernel_plotter(kernel, data, bins, bandwidth):\n",
        "    plt.hist(data, bins=bins, density=True)\n",
        "    X_plot = np.linspace(data.min(), data.max(), 1000)[:, np.newaxis]\n",
        "    kde = KernelDensity(kernel=kernel, bandwidth=bandwidth).fit(data.reshape(-1, 1))\n",
        "    log_dens = kde.score_samples(X_plot)\n",
        "    plt.plot(X_plot[:, 0], np.exp(log_dens))\n",
        "    plt.title(f\"Kernel = '{kernel}', h={bandwidth}\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6abe857a954ddf896b531e1340bc75cd",
          "grade": false,
          "grade_id": "cell-ebe9992d733479b9",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "Zhaqoom7BtiH"
      },
      "source": [
        "kernel_plotter(\"tophat\", vals, fd_bins, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4edf0cc813d30af104a5abef2b9521ad",
          "grade": false,
          "grade_id": "cell-52c6730dc8c307eb",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "mE4u1tcMBtiJ"
      },
      "source": [
        "The tophat, or uniform, kernel will look closest to the actual histogram with sufficient bins."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e3b993c3219be24fcb710eb5520c3af0",
          "grade": false,
          "grade_id": "cell-59e1a4bc334f42b4",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "Zb2-r9tgBtiJ"
      },
      "source": [
        "Now you will plot the various kernels with the same bandwidth value for the data we've been examining. Then you'll plot a variety of densities with the same kernel but different bandwidths. Try out different values and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ccb209e924c4428e37308a44a8cfa59e",
          "grade": false,
          "grade_id": "cell-71818a37afacf52c",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "umwprtW2BtiJ"
      },
      "source": [
        "for kernel in [\"gaussian\",\"tophat\",\"epanechnikov\",\"exponential\",\"linear\",\"cosine\"]:\n",
        "    kernel_plotter(kernel, vals, fd_bins, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b5a68ba1b19a72479e61f872404a06b7",
          "grade": false,
          "grade_id": "cell-541a9e14975dbd2e",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "Td3zOV-WBtiL"
      },
      "source": [
        "for bandwidth in [0.2, 0.5, 0.8, 1, 1.5, 2]:\n",
        "    kernel_plotter(\"tophat\", vals, fd_bins, bandwidth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "54ba3e8972fa57ff02f66a22250c6db2",
          "grade": false,
          "grade_id": "cell-2c1f22d1e6c1dc8f",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "6Wr3_XtTBtiN"
      },
      "source": [
        "# Select what you think as the best kernel and best bandwidth\n",
        "# Set them to best_kernel and best_bandwidth respectively\n",
        "best_kernel = \"tophat\"\n",
        "best_bandwidth = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "59f896df0b938a10a16f919e103a4d8d",
          "grade": true,
          "grade_id": "cell-ad9b81ffe7bbfabd",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false
        },
        "id": "FV4lgLVMBtiO"
      },
      "source": [
        "assert isinstance(best_kernel, str)\n",
        "assert best_kernel in [\"gaussian\",\"tophat\",\"epanechnikov\",\"exponential\",\"linear\",\"cosine\"]\n",
        "assert isinstance(best_bandwidth, float)\n",
        "assert best_bandwidth > 0\n",
        "assert best_bandwidth <= 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "512bd5f5ada1640bfe1ecf97ba40b895",
          "grade": false,
          "grade_id": "cell-687d6638954cd5c1",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "KUxTkPm3BtiQ"
      },
      "source": [
        "## Density-Based Clustering\n",
        "\n",
        "Here's the clustering overview from the manifold clustering exercise again. Now most of the remaining clustering methods should make sense as well.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3e4891b9826fe3ea9eeaff57aafe2401",
          "grade": false,
          "grade_id": "cell-ef7f28d087f7d3aa",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "KAYsFU4BBtiQ"
      },
      "source": [
        "import time\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import cluster, datasets, mixture\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from itertools import cycle, islice\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# ============\n",
        "# Generate datasets. We choose the size big enough to see the scalability\n",
        "# of the algorithms, but not too big to avoid too long running times\n",
        "# ============\n",
        "n_samples = 1500\n",
        "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=.5,\n",
        "                                      noise=.05)\n",
        "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
        "blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)\n",
        "no_structure = np.random.rand(n_samples, 2), None\n",
        "\n",
        "# Anisotropicly distributed data\n",
        "random_state = 170\n",
        "X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
        "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
        "X_aniso = np.dot(X, transformation)\n",
        "aniso = (X_aniso, y)\n",
        "\n",
        "# blobs with varied variances\n",
        "varied = datasets.make_blobs(n_samples=n_samples,\n",
        "                             cluster_std=[1.0, 2.5, 0.5],\n",
        "                             random_state=random_state)\n",
        "\n",
        "# ============\n",
        "# Set up cluster parameters\n",
        "# ============\n",
        "plt.figure(figsize=(9 * 2 + 3, 12.5))\n",
        "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n",
        "                    hspace=.01)\n",
        "\n",
        "plot_num = 1\n",
        "\n",
        "default_base = {'quantile': .3,\n",
        "                'eps': .3,\n",
        "                'damping': .9,\n",
        "                'preference': -200,\n",
        "                'n_neighbors': 10,\n",
        "                'n_clusters': 3}\n",
        "\n",
        "datasets = [\n",
        "    (noisy_circles, {'damping': .77, 'preference': -240,\n",
        "                     'quantile': .2, 'n_clusters': 2}),\n",
        "    (noisy_moons, {'damping': .75, 'preference': -220, 'n_clusters': 2}),\n",
        "    (varied, {'eps': .18, 'n_neighbors': 2}),\n",
        "    (aniso, {'eps': .15, 'n_neighbors': 2}),\n",
        "    (blobs, {}),\n",
        "    (no_structure, {})]\n",
        "\n",
        "for i_dataset, (dataset, algo_params) in enumerate(datasets):\n",
        "    # update parameters with dataset-specific values\n",
        "    params = default_base.copy()\n",
        "    params.update(algo_params)\n",
        "\n",
        "    X, y = dataset\n",
        "\n",
        "    # normalize dataset for easier parameter selection\n",
        "    X = StandardScaler().fit_transform(X)\n",
        "\n",
        "    # estimate bandwidth for mean shift\n",
        "    bandwidth = cluster.estimate_bandwidth(X, quantile=params['quantile'])\n",
        "\n",
        "    # connectivity matrix for structured Ward\n",
        "    connectivity = kneighbors_graph(\n",
        "        X, n_neighbors=params['n_neighbors'], include_self=False)\n",
        "    # make connectivity symmetric\n",
        "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
        "\n",
        "    # ============\n",
        "    # Create cluster objects\n",
        "    # ============\n",
        "    ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
        "    two_means = cluster.MiniBatchKMeans(n_clusters=params['n_clusters'])\n",
        "    ward = cluster.AgglomerativeClustering(\n",
        "        n_clusters=params['n_clusters'], linkage='ward',\n",
        "        connectivity=connectivity)\n",
        "    spectral = cluster.SpectralClustering(\n",
        "        n_clusters=params['n_clusters'], eigen_solver='arpack',\n",
        "        affinity=\"nearest_neighbors\")\n",
        "    dbscan = cluster.DBSCAN(eps=params['eps'])\n",
        "    affinity_propagation = cluster.AffinityPropagation(\n",
        "        damping=params['damping'], preference=params['preference'])\n",
        "    average_linkage = cluster.AgglomerativeClustering(\n",
        "        linkage=\"average\", affinity=\"cityblock\",\n",
        "        n_clusters=params['n_clusters'], connectivity=connectivity)\n",
        "    birch = cluster.Birch(n_clusters=params['n_clusters'])\n",
        "    gmm = mixture.GaussianMixture(\n",
        "        n_components=params['n_clusters'], covariance_type='full')\n",
        "\n",
        "    clustering_algorithms = (\n",
        "        ('MiniBatchKMeans', two_means),\n",
        "        ('AffinityPropagation', affinity_propagation),\n",
        "        ('MeanShift', ms),\n",
        "        ('SpectralClustering', spectral),\n",
        "        ('Ward', ward),\n",
        "        ('AgglomerativeClustering', average_linkage),\n",
        "        ('DBSCAN', dbscan),\n",
        "        ('Birch', birch),\n",
        "        ('GaussianMixture', gmm)\n",
        "    )\n",
        "\n",
        "    for name, algorithm in clustering_algorithms:\n",
        "        t0 = time.time()\n",
        "\n",
        "        # catch warnings related to kneighbors_graph\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.filterwarnings(\n",
        "                \"ignore\",\n",
        "                message=\"the number of connected components of the \" +\n",
        "                \"connectivity matrix is [0-9]{1,2}\" +\n",
        "                \" > 1. Completing it to avoid stopping the tree early.\",\n",
        "                category=UserWarning)\n",
        "            warnings.filterwarnings(\n",
        "                \"ignore\",\n",
        "                message=\"Graph is not fully connected, spectral embedding\" +\n",
        "                \" may not work as expected.\",\n",
        "                category=UserWarning)\n",
        "            algorithm.fit(X)\n",
        "\n",
        "        t1 = time.time()\n",
        "        if hasattr(algorithm, 'labels_'):\n",
        "            y_pred = algorithm.labels_.astype(np.int)\n",
        "        else:\n",
        "            y_pred = algorithm.predict(X)\n",
        "\n",
        "        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n",
        "        if i_dataset == 0:\n",
        "            plt.title(name, size=18)\n",
        "\n",
        "        colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n",
        "                                             '#f781bf', '#a65628', '#984ea3',\n",
        "                                             '#999999', '#e41a1c', '#dede00']),\n",
        "                                      int(max(y_pred) + 1))))\n",
        "        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n",
        "\n",
        "        plt.xlim(-2.5, 2.5)\n",
        "        plt.ylim(-2.5, 2.5)\n",
        "        plt.xticks(())\n",
        "        plt.yticks(())\n",
        "        plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n",
        "                 transform=plt.gca().transAxes, size=15,\n",
        "                 horizontalalignment='right')\n",
        "        plot_num += 1\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bb01399b8fdb70164d81285e341eaffe",
          "grade": false,
          "grade_id": "cell-0947a62caa6656ae",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "xXjjyHuoBtiR"
      },
      "source": [
        "## Feedback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ed936ab53a1391c5e6af8df699a1dbf5",
          "grade": false,
          "grade_id": "feedback",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "bQ8UV_XcBtiS"
      },
      "source": [
        "def feedback():\n",
        "    \"\"\"Provide feedback on the contents of this exercise\n",
        "    \n",
        "    Returns:\n",
        "        string\n",
        "    \"\"\"\n",
        "    return \"All good!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f39f6185a54850c2f1f9b5b2a17b7543",
          "grade": true,
          "grade_id": "feedback-tests",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false
        },
        "id": "y2LDfOWaBtiU"
      },
      "source": [
        "print(feedback())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}